{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#azure-ai-foundry-architecture","title":"Azure AI Foundry Architecture","text":"<p>The Azure AI Foundry provides a unified experience for both AI developers and data scientists to build, evaluate, and deploy AI models through a web portal, SDK, or CLI. The Azure AI Foundry is built on capabilities and services provided by other Azure services.</p> The Azure AI Foundry Architecture (click to expand) <p>The figure below provides the big picture of the core components and capabilities provide to support end-to-end development of enterprise-grade generative AI solutions.</p> <p></p>"},{"location":"#rag-chat-app-workshops","title":"RAG Chat App Workshops","text":"<p>This repository contains the source and instructions guide for a workshop that takes you step-by-step through the process of building a RAG-based chat app using Azure AI Foundry. </p> <p>The Guide has TWO Learning Paths - Pick one! \ud83c\udd95</p> <p>Pick the path that reflects your interest and experience level: </p> <ul> <li>The Hybrid Workshop is derived from the official 3-part tutorial and uses both the Azure AI Foundry Portal (for setup) and Azure AI Foundry Python SDK (for ideation &amp; evaluation). This is a code-first experience.</li> <li>The Portal First Workshop focuses on using the Azure AI Foundry Portal to maximize the end-to-end development workflow without SDK. This is a low-code experience.</li> </ul>"},{"location":"#pre-requisites","title":"Pre-Requisites","text":"<p>To get the most from this lab, you will need the following:</p> <ol> <li>An Azure subscription - Get one for free</li> <li>A GitHub account - Get one for free</li> <li>Familiarity with VS Code, Github &amp; Azure.</li> <li>Familiarity with Python and Jupyter Notebooks.</li> </ol> <p>Verify: Your Azure subscription has sufficient quota to deploy these models:</p> <ol> <li>Chat: <code>gpt-4o-mini</code> </li> <li>Embeddings: <code>text-embedding-ada-002</code></li> </ol> <p>Verify: Your Azure account is authorized to make role assignments for Azure AI resources. This may involve having a Privileged role like Owner, User Access Admin or RBAC Admin.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>This repository is instrumented with a <code>devcontainer.json</code> to give you a development environment with all required dependencies pre-installed. To get started:</p> <ol> <li> <p>Fork the repository to your personal profile. Visit your fork in the browser.</p> </li> <li> <p>Launch Codespaces on that fork. Setup will take a few minutes.</p> </li> <li> <p>Type this command into the VS Code terminal when ready. A dialog will pop up.</p> <pre><code>mkdocs serve\n</code></pre> </li> <li> <p>Select the \"View in browser\" option in the pop-up dialog. You should see this guide.</p> </li> <li> <p>Open a second VS Code terminal pane. Use that for all further instructions.</p> </li> </ol>"},{"location":"1-Hybrid-Workshop/1-Overview/00/","title":"1.1 Learning Objectives","text":"<p>This is based on the Build a custom chat app with the Azure AI Foundry SDK tutorial but adapted for use in workshops with a devcontainer for fast setup. Fork the repo, launch GitHub Codespaces - and get started!</p> <p>The lab teaches you to build a RAG-based copilot using the Azure AI Foundry platform By completing this lab, you will learn to do the following tasks:</p> <ol> <li>Use the Azure AI Foundry Portal to<ul> <li>start a new Azure AI project</li> <li>discover and deploy AI models to the project</li> <li>add an Azure AI Search resource to the project</li> <li>setup an Application Insights resource for tracing</li> </ul> </li> <li>Use the Azure AI Foundry SDK to<ul> <li>create a new search index with your data</li> <li>extract customer intent with an intent mapping prompt template</li> <li>retrieve relevant knowledge using the search index</li> <li>create a chat agent with a grounded prompt template</li> <li>process customer queries returning responses grounded in my data.</li> </ul> </li> <li>Use the Azure AI Evaluation SDK to assess app quality by<ul> <li>creating a custom evaluation dataset.</li> <li>executing a custom evaluation workflow.</li> <li>viewing evaluation results, in your local environment.</li> <li>viewing evaluation results, in Azure AI Foundry portal.</li> </ul> </li> </ol> <p>This sets you up with a \"sandbox\" project that you can use to explore other features or tooling in Azure AI Foundry. For example - try bringing your own application data, or adding secondary data sources for knowledge retrieval as part of the RAG flow.</p> BONUS: Use what you learn here to explore Contoso Chat next! (click to expand) <p>Contoso Chat is an open-source reference sample that implements the retail RAG-based copilot (using the same data) in a code-first approach from initial provisioning to final production deployment. </p> <ul> <li>The current version (v3) provisions the Azure AI Foundry resources using the Azure Developer CLI (<code>azd provision</code>) and deploys the final application to Azure Container Apps for a hosted API endpoint.</li> <li>The next version (v4) will incorporate more elements from the Azure AI Foundry SDKs that we highlight in this RAG tutorial, including use of the Azure AI Model Inference API and the Azure AI Evaluation SDK.</li> </ul>"},{"location":"1-Hybrid-Workshop/1-Overview/01/","title":"1.2 Application Scenario","text":"<p>In this tutorial, we build a retail chat AI (copilot) that uses Retrieval Augmented Generation (RAG) to ground the chat responses in the retailer's own data. Let's briefly review what this means.</p>"},{"location":"1-Hybrid-Workshop/1-Overview/01/#1-rag-chat-app-tutorial","title":"1. RAG Chat App (tutorial)","text":"<p>This RAG Chat tutorial provides a quickstart for building and evaluating a basic RAG-based copilot using the Azure AI Foundry portal and SDK. The tutorial is grounded in the Contoso Outdoors retailer data and combines both low-code (Portal) and code-first (SDK) steps to teach the latest Azure AI Foundry tools and features. Think of this as a sandbox for open exploration</p> <p>The figure explains the RAG pattern visually:</p> <ol> <li>The user question (prompt) is received at the copilot hosted endpoint</li> <li>The question is used to retrieve related knowledge from relevant sources.</li> <li>The prompt is then augmented with knowledge as context, and sent to the model.</li> <li>The model now generates a response that is \"grounded\" in this knowledge context.</li> </ol> <p></p>"},{"location":"1-Hybrid-Workshop/1-Overview/01/#2-contoso-outdoor-chat-ui","title":"2. Contoso Outdoor (chat UI)","text":"<p>Contoso Outdoor is a fictitious enterprise retailer specializing in hiking and camping gear for outdoor enthusiasts. Their website (chat UI) provides customers with a catalog of their products, with product pages offering detailed information for user review. We'll look at the retailer data sources in the next section.</p> <p></p>"},{"location":"1-Hybrid-Workshop/1-Overview/01/#3-contoso-chat-chat-ai","title":"3. Contoso Chat (chat AI)","text":"<p>The chat UI shown is not used in THIS workshop - but code is open-source if useful.</p> <p>Contoso Chat is the open-source reference implementation of a custom RAG-based retail copilot based on the Contoso Outdoor retail scenario. It is implemented as an AI App Template that can be provisioned and deployed to Azure Container Apps to provide a hosted API endpoint. Customer requests on the chat UI (website) are now directed to this chat AI (endpoint) for processing, allowing for the user experience shown below.</p> <p></p>"},{"location":"1-Hybrid-Workshop/1-Overview/02/","title":"1.3 Application Data","text":"<p>The Retrieval Augmented Generation (RAG) design pattern allows us to customize the AI by enhancing the user prompt with dynamically retrieved knowledge that grounds the responses in the provided context. Let's understand the shape of the data available to us - and think proactively about how you could bring your data into this mix.</p>"},{"location":"1-Hybrid-Workshop/1-Overview/02/#1-customer-info","title":"1. Customer Info","text":"<p>This record represents a single customer, providing their profile information (\"id\", name, contact info) and their purchase history (\"orders\"). This JSON data may be stored in a noSQL datbase like Azure CosmosDB and retrieved dynamically by the chat AI.</p> SAMPLE DATA (JSON) - click to expand <pre><code>{\n    \"id\": \"1\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Smith\",\n    \"age\": 35,\n    \"email\": \"johnsmith@example.com\",\n    \"phone\": \"555-123-4567\",\n    \"address\": \"123 Main St,  Anytown USA, 12345\",\n    \"membership\": \"Base\",\n\n    \"orders\": [\n    {\n        \"id\": 29,\n        \"productId\": 8,\n        \"quantity\": 2,\n        \"total\": 700.0,\n        \"date\": \"2/10/2023\",\n        \"name\": \"Alpine Explorer Tent\",\n        \"unitprice\": 350.0,\n        \"category\": \"Tents\",\n        \"brand\": \"AlpineGear\",\n        \"description\": \"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\"\n    },\n    {\n        \"id\": 1,\n        \"productId\": 1,\n        \"quantity\": 2,\n        \"total\": 500.0,\n        \"date\": \"1/5/2023\",\n        \"name\": \"TrailMaster X4 Tent\",\n        \"unitprice\": 250.0,\n        \"category\": \"Tents\",\n        \"brand\": \"OutdoorLiving\",\n        \"description\": \"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\"\n    },\n    {\n        \"id\": 19,\n        \"productId\": 5,\n        \"quantity\": 1,\n        \"total\": 60.0,\n        \"date\": \"1/25/2023\",\n        \"name\": \"BaseCamp Folding Table\",\n        \"unitprice\": 60.0,\n        \"category\": \"Camping Tables\",\n        \"brand\": \"CampBuddy\",\n        \"description\": \"CampBuddy's BaseCamp Folding Table is an adventurer's best friend. Lightweight yet powerful, the table is a testament to fun-meets-function and will elevate any outing to new heights. Crafted from resilient, rust-resistant aluminum, the table boasts a generously sized 48 x 24 inches tabletop, perfect for meal times, games and more. The foldable design is a godsend for on-the-go explorers. Adjustable legs rise to the occasion to conquer uneven terrains and offer height versatility, while the built-in handle simplifies transportation. Additional features like non-slip feet, integrated cup holders and mesh pockets add a pinch of finesse. Quick to set up without the need for extra tools, this table is a silent yet indispensable sidekick during camping, picnics, and other outdoor events. Don't miss out on the opportunity to take your outdoor experiences to a new level with the BaseCamp Folding Table. Get yours today and embark on new adventures tomorrow!\"\n    }]\n}\n</code></pre>"},{"location":"1-Hybrid-Workshop/1-Overview/02/#2-product-manual-info","title":"2. Product Manual Info","text":"<p>This record represents a single product in the retailer's catalog with extensive text (formatted as Markdown) covering information like brand, category, features, technical specs, user guide, cautions, warranty information, return policy, reviews, FAQ. This information may be used for building the Contoso Web UI, and potentially for grounding responses related to richer QA later. </p> <p>The product info has been rendered as a Markmap for visual clarity. Simply zoom in/out or pan in/out to explore the content. You can click on any node (circle) to expand/collapse its sub-tree. You may need to refresh or reload page to re-render the tree.</p> SAMPLE RECORD (Markdown) - click to expand # Information about product item_number: 1
TrailMaster X4 Tent, price $250,

## Brand
OutdoorLiving

## Category
Tents

## Features
- Polyester material for durability
- Spacious interior to accommodate multiple people
- Easy setup with included instructions
- Water-resistant construction to withstand light rain
- Mesh panels for ventilation and insect protection
- Rainfly included for added weather protection
- Multiple doors for convenient entry and exit
- Interior pockets for organizing small items
- Reflective guy lines for improved visibility at night
- Freestanding design for easy setup and relocation
- Carry bag included for convenient storage and transportation

## Technical Specs
**Best Use**: Camping  
**Capacity**: 4-person  
**Season Rating**: 3-season  
**Setup**: Freestanding  
**Material**: Polyester  
**Waterproof**: Yes  
**Floor Area**: 80 square feet  
**Peak Height**: 6 feet  
**Number of Doors**: 2  
**Color**: Green  
**Rainfly**: Included  
**Rainfly Waterproof Rating**: 2000mm  
**Tent Poles**: Aluminum  
**Pole Diameter**: 9mm  
**Ventilation**: Mesh panels and adjustable vents  
**Interior Pockets**: Yes (4 pockets)  
**Gear Loft**: Included  
**Footprint**: Sold separately  
**Guy Lines**: Reflective  
**Stakes**: Aluminum  
**Carry Bag**: Included  
**Dimensions**: 10ft x 8ft x 6ft (length x width x peak height)  
**Packed Size**: 24 inches x 8 inches  
**Weight**: 12 lbs  

## User Guide

### Introduction

Thank you for choosing the TrailMaster X4 Tent. This user guide provides instructions on how to set up, use, and maintain your tent effectively. Please read this guide thoroughly before using the tent.

### Package Contents

Ensure that the package includes the following components:

- TrailMaster X4 Tent body
- Tent poles
- Rainfly (if applicable)
- Stakes and guy lines
- Carry bag
- User Guide

If any components are missing or damaged, please contact our customer support immediately.

### Tent Setup

#### Step 1: Selecting a Suitable Location

- Find a level and clear area for pitching the tent.
- Remove any sharp objects or debris that could damage the tent floor.

#### Step 2: Unpacking and Organizing Components

- Lay out all the tent components on the ground.
- Familiarize yourself with each part, including the tent body, poles, rainfly, stakes, and guy lines.

#### Step 3: Assembling the Tent Poles

- Connect the tent poles according to their designated color codes or numbering.
- Slide the connected poles through the pole sleeves or attach them to the tent body clips.

#### Step 4: Setting up the Tent Body

- Begin at one end and raise the tent body by pushing up the poles.
- Ensure that the tent body is evenly stretched and centered.
- Secure the tent body to the ground using stakes and guy lines as needed.

#### Step 5: Attaching the Rainfly (if applicable)

- If your tent includes a rainfly, spread it over the tent body.
- Attach the rainfly to the tent corners and secure it with the provided buckles or clips.
- Adjust the tension of the rainfly to ensure proper airflow and weather protection.

#### Step 6: Securing the Tent

- Stake down the tent corners and guy out the guy lines for additional stability.
- Adjust the tension of the guy lines to provide optimal stability and wind resistance.

### Tent Takedown and Storage

#### Step 1: Removing Stakes and Guy Lines

- Remove all stakes from the ground.
- Untie or disconnect the guy lines from the tent and store them separately.

#### Step 2: Taking Down the Tent Body

- Start by collapsing the tent poles carefully.
- Remove the poles from the pole sleeves or clips.
- Collapse the tent body and fold it neatly.

#### Step 3: Disassembling the Tent Poles

- Disconnect and separate the individual pole sections.
- Store the poles in their designated bag or sleeve.

#### Step 4: Packing the Tent

- Fold the tent body tightly and place it in the carry bag.
- Ensure that the rainfly and any other components are also packed securely.

### Tent Care and Maintenance

- Clean the tent regularly with mild soap and water.
- Avoid using harsh chemicals or abrasive cleaners.
- Allow the tent to dry completely before storing it.
- Store the tent in a cool, dry place away from direct sunlight.

## Cautions
1. **Avoid Uneven or Rocky Surfaces**: Do not place the tent on uneven or rocky surfaces.
2. **Stay Clear of Hazardous Areas**: Avoid setting up the tent near hazardous areas.
3. **No Open Flames or Heat Sources**: Do not use open flames, candles, or any other flammable heat sources near the tent.
4. **Avoid Overloading**: Do not exceed the maximum weight capacity or overload the tent with excessive gear or equipment.
5. **Don't Leave Unattended**: Do not leave the tent unattended while open or occupied.
6. **Avoid Sharp Objects**: Keep sharp objects away from the tent to prevent damage to the fabric or punctures.
7. **Avoid Using Harsh Chemicals**: Do not use harsh chemicals or abrasive cleaners on the tent, as they may damage the material.
8. **Don't Store Wet**: Do not store the tent when it is wet or damp, as it can lead to mold, mildew, or fabric deterioration.
9. **Avoid Direct Sunlight**: Avoid prolonged exposure of the tent to direct sunlight, as it can cause fading or weakening of the fabric.
10. **Don't Neglect Maintenance**: Regularly clean and maintain the tent according to the provided instructions to ensure its longevity and performance.

## Warranty Information
Thank you for purchasing the TrailMaster X4 Tent. We are confident in the quality and durability of our product. This warranty provides coverage for any manufacturing defects or issues that may arise during normal use of the tent. Please read the terms and conditions of the warranty below:

1. **Warranty Coverage**: The TrailMaster X4 Tent is covered by a **2-year limited warranty** from the date of purchase. This warranty covers manufacturing defects in materials and workmanship.

2. **What is Covered**:
- Seam or fabric tears that occur under normal use and are not a result of misuse or abuse.
- Issues with the tent poles, zippers, buckles, or other hardware components that affect the functionality of the tent.
- Problems with the rainfly or other included accessories that impact the performance of the tent.

3. **What is Not Covered**:
- Damage caused by misuse, abuse, or improper care of the tent.
- Normal wear and tear or cosmetic damage that does not affect the functionality of the tent.
- Damage caused by extreme weather conditions, natural disasters, or acts of nature.
- Any modifications or alterations made to the tent by the user.

4. **Claim Process**:
- In the event of a warranty claim, please contact our customer support (contact details provided in the user guide) to initiate the process.
- Provide proof of purchase, including the date and place of purchase, along with a detailed description and supporting evidence of the issue.

5. **Resolution Options**:
- Upon receipt of the warranty claim, our customer support team will assess the issue and determine the appropriate resolution.
- Options may include repair, replacement of the defective parts, or, if necessary, replacement of the entire tent.

6. **Limitations and Exclusions**:
- Our warranty is non-transferable and applies only to the original purchaser of the TrailMaster X4 Tent.
- The warranty does not cover any incidental or consequential damages resulting from the use or inability to use the tent.
- Any unauthorized repairs or alterations void the warranty.

### Contact Information

If you have any questions or need further assistance, please contact our customer support:

- Customer Support Phone: +1-800-123-4567
- Customer Support Email: support@example.com

## Return Policy
- **If Membership status "None        ":**  Returns are accepted within 30 days of purchase, provided the tent is unused, undamaged and in its original packaging. Customer is responsible for the cost of return shipping. Once the returned item is received, a refund will be issued for the cost of the item minus a 10% restocking fee. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.
- **If Membership status "Gold":**  Returns are accepted within 60 days of purchase, provided the tent is unused, undamaged and in its original packaging. Free return shipping is provided. Once the returned item is received, a full refund will be issued. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.
- **If Membership status "Platinum":**  Returns are accepted within 90 days of purchase, provided the tent is unused, undamaged and in its original packaging. Free return shipping is provided, and a full refund will be issued. If the item was damaged during shipping or if there is a defect, the customer should contact customer service within 7 days of receiving the item.

## Reviews
1) **Rating:** 5
**Review:** I am extremely happy with my TrailMaster X4 Tent! It's spacious, easy to set up, and kept me dry during a storm. The UV protection is a great addition too. Highly recommend it to anyone who loves camping!

2) **Rating:** 3
**Review:** I bought the TrailMaster X4 Tent, and while it's waterproof and has a spacious interior, I found it a bit difficult to set up. It's a decent tent, but I wish it were easier to assemble.

3) **Rating:** 5
**Review:** The TrailMaster X4 Tent is a fantastic investment for any serious camper. The easy setup and spacious interior make it perfect for extended trips, and the waterproof design kept us dry in heavy rain.

4) **Rating:** 4
**Review:** I like the TrailMaster X4 Tent, but I wish it came in more colors. It's comfortable and has many useful features, but the green color just isn't my favorite. Overall, it's a good tent.

5) **Rating:** 5
**Review:** This tent is perfect for my family camping trips. The spacious interior and convenient storage pocket make it easy to stay organized. It's also super easy to set up, making it a great addition to our gear.

## FAQ
1) Can the TrailMaster X4 Tent be used in winter conditions?
The TrailMaster X4 Tent is designed for 3-season use and may not be suitable for extreme winter conditions with heavy snow and freezing temperatures.

2) How many people can comfortably sleep in the TrailMaster X4 Tent?
The TrailMaster X4 Tent can comfortably accommodate up to 4 people with room for their gear.

3) Is there a warranty on the TrailMaster X4 Tent?
Yes, the TrailMaster X4 Tent comes with a 2-year limited warranty against manufacturing defects.

4) Are there any additional accessories included with the TrailMaster X4 Tent?
The TrailMaster X4 Tent includes a rainfly, tent stakes, guy lines, and a carry bag for easy transport.

5) Can the TrailMaster X4 Tent be easily carried during hikes?
Yes, the TrailMaster X4 Tent weighs just 12lbs, and when packed in its carry bag, it can be comfortably carried during hikes."},{"location":"1-Hybrid-Workshop/1-Overview/02/#3-product-catalog-info","title":"3. Product Catalog Info","text":"<p>This record represents a single product item in the product catalog database, with a unique product ID. The <code>products.csv</code> file contains a collection of these records, representing the entire Contoso Outdoors product catalog at a high level. </p> <p>Each product ID has a corresponding \"product manual\" record that provides more extensive detail (e.g, in website pages). The product catalog entry itself contains just the {id, name, price, category, brand, description} information required for creating product indexes and searching for matching results (for later retrieval) based on a customer query. </p> <p>The catalog record below corresponds to the product manual record above.</p> SAMPLE RECORD (CSV) - click to expand <pre><code>id = 1,\nname = TrailMaster X4 Tent,\nprice = 250.0,\ncategory = Tents,\nbrand = OutdoorLiving,\ndescription = \"Unveiling the TrailMaster X4 Tent from \\\n    OutdoorLiving, your home away from home for your next \\\n    camping adventure. Crafted from durable polyester, \\\n    this tent boasts a spacious interior perfect for four \\\n    occupants. It ensures your dryness under drizzly skies \\\n    thanks to its water-resistant construction, and the \\\n    accompanying rainfly adds an extra layer of weather \\\n    protection. It offers refreshing airflow and bug defence, \\\n    courtesy of its mesh panels. Accessibility is not an issue \\\n    with its multiple doors and interior pockets that keep \\\n    small items tidy. Reflective guy lines grant better \\\n    visibility at night, and the freestanding design \\\n    simplifies setup and relocation. With the included \\\n    carry bag, transporting this convenient abode becomes \\\n    a breeze. Be it an overnight getaway or a week-long nature \\\n    escapade, the TrailMaster X4 Tent provides comfort, \\\n    convenience, and concord with the great outdoors. Comes with \\\n    a two-year limited warranty to ensure customer satisfaction.\"\n</code></pre>"},{"location":"1-Hybrid-Workshop/1-Overview/03/","title":"1.4 RAG Chat Tutorial","text":"<p>This markmap provides the big picture for navigating this RAG Chat tutorial. Learn to build a minimal RAG-based copilot experience using Azure AI Foundry Portal (for setup) and Azure AI Foundry SDK (for ideation and evaluation).</p> <p>RAG Chat Roadmap: Refresh this page to see markmap if needed</p> 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"},{"location":"1-Hybrid-Workshop/2-Setup/01/","title":"2.1 Create AI Project","text":"<p>This is Part 1 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY PORTAL</p> <p>At the end of this section, you should have provisioned an Azure AI Hub and Azure AI project resource, setup an Azure AI Search resource and deployed two Azure OpenAI models for implementing the RAG-based copilot. You should also have launched GitHub Codespaces and configured your development environment to work with your provisioned Azure infrastructure.</p>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#1-log-into-azure-ai-foundry","title":"1. Log Into Azure AI Foundry","text":"<ol> <li>Open a private browser and navigate to https://ai.azure.com.</li> <li>Log in with an active Azure subscription. Note the tenant ID if multi-tenant.</li> <li>You should see a landing page with a blue \"+ Create project\" button as shown below.      </li> </ol> <p>Note: If you had previously created projects, those will be listed as shown above. Don't worry if you don't see any listed for your profile. We are going to create a new project next.</p>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#2-create-a-new-project","title":"2. Create a new project","text":"<ol> <li> <p>Click the \"+ Create project\" button. You should see a dialog popup like this. Your default project name and hub information will be different and reflect your prior activity.     </p> </li> <li> <p>Change the default project name to something memorable - I used <code>ninarasi-ragchat-v1</code>.</p> </li> <li>We also want to create a new hub for our new AI project - let's fix that next in the dialog.</li> </ol> TROUBLESHOOTING: Your Create a project dialog looks different. (Click to expand) <p>You may see a dialog like this instead. This is typically the case when you don't have a pre-existing Hub selection and the workflow now automatically adds a default Hub resource. In this case, customize the project name as specified in step 1 above, then skip the step 3 below and go directly to customize the hub name as described in step 4 to complete the dialog.</p> <p></p>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#3-create-new-hub","title":"3. Create new hub","text":"<ol> <li>Click the <code>Create new hub</code> (blue lettering) in dialog above.</li> <li>Pick a memorable name that reflects the project - I used <code>ninarasi-ragchat-hub</code> </li> <li>Click \"Next\". It returns you to the previous dialog, with an enhanced view as shown     </li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#4-customize-the-hub","title":"4. Customize the hub","text":"<ol> <li>Click the \"Customize\" button in that dialog. This lets you customize the defaults as shown.</li> <li>First, select a relevant Location with relevant model quota - I used <code>East US2</code> </li> <li>Next,customize the resource group name to be memorable - I used <code>ninarasi-ragchat-rg</code> </li> <li>Next, click \"Create new AI Search\" (blue lettering) in the dialog to trigger a new pop-up</li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#5-create-new-ai-search","title":"5. Create new AI Search","text":"<ol> <li>Customize resource name - I used <code>ninarasi-ragchat-aisearch</code> - then hit Next.     </li> <li>You return to the Create a project wizard - hit Next to get to review.     </li> <li>Review the details one last time - hit Create to confirm AI project creation.     </li> <li>Creation takes a few minutes - all elements will show green on success.     </li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/01/#6-review-created-ai-project","title":"6. Review Created AI Project","text":"<ol> <li>You should automatically be taken to the AI Project overview page as shown. Note the Project connection string under <code>Project details</code> - we'll revisit it later.     </li> <li>Click on the Open in management center link (highlighted in red) - it takes you to this Management Center view. Clicking <code>Go to project</code> will take you back to the AI project.     </li> <li>However, for now click on the Connected Resources option in the sidebar. This lets us see which resources can be accessed via the Project connection we noted earlier. Verify that Azure AI Search is one of the listed resources.     </li> </ol> <p>CONGRATULATIONS! You created your Azure AI Hub &amp; Project resources</p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/","title":"2.2 Deploy AI Models","text":"<p>Let's revisit our Retrieval Augmented Generation design pattern. Note that we make use of two models to implement this design architecture.</p> <ol> <li>A Large Language Model (Embedding) for vectorizing the user query.</li> <li>A Large Language Model (Chat) for generating the response returned to user.</li> </ol> <p></p> <p>Let's find the right models to use and deploy them to our Azure AI project so we can use them in our RAG-based copilot implementation. Start by navigating to the Azure AI Project overview page. Then select the Models + endpoints link under My assets.</p> <p></p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#1-deploy-chat-model","title":"1. Deploy Chat Model","text":""},{"location":"1-Hybrid-Workshop/2-Setup/02/#11-select-a-chat-model","title":"1.1. Select A Chat Model","text":"<ol> <li> <p>Click the blue \"Deploy model\" button and pick Deploy base model from the dropdown options.</p> <p></p> </li> <li> <p>If you know the specific model to use, you can search for it here. In our case, let's look at what our options are. First, click the Collections filter and select Azure OpenAI. Next, click the Inference tasks filter and select Chat completion. We can see that this reduces our choices from 1800+ models in the Azure AI model catalog to 9 matching models.</p> <p></p> </li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#12-deploy-the-chat-model","title":"1.2. Deploy the Chat Model","text":"<ol> <li>We can pick any of those options as shown above, to see a Model Card with more details. Let's pick <code>gpt-4o-mini</code> and click Confirm to get this deployment wizard. Note that it selects a Global Standard deployment type by default. The deployment has a default capacity of 10K tokens per minute (TPM) which can be useful when we begin the evaluation phase.</li> </ol> <ol> <li>Click on the dropdown to see other Deployment type options. Read the documentation to learn more about what each provides. Global Standard is the recommended starting place for customers so let's go with that.</li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#13-verify-deployment","title":"1.3. Verify Deployment","text":"<p>On successful deployment, you will be taken to the model deployment page where you can review the details and retrieve relevant information like the Endpoint and Key information, for use with code-first clients.</p> <p></p> <p>You can Open in playground and use the Azure AI Portal as an ideation tool to explore different prompt templates, model configurations and multi-turn conversational approaches to determine if this model is in fact suitable for your app scenario.</p> <p>Task: Ask the model to <code>Tell me about hiking boots for my trip to Spain</code> - is response grounded?</p> <p></p> <p>Homework: Complete the Deploy an enterprise chat app tutorial with your data. Is response grounded now?</p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#14-view-metrics","title":"1.4. View Metrics","text":"<p>You can also select the Metrics tab of deployed models within an Azure AI project to get metrics about the cost (tokens) and performance (requests) of that model in a given time frame. The screenshot shows the data taken for this model after completing the entire project. The spike reflects the requests made during the evaluation stage of the workflow.</p> <p></p> <p>You can also click the Open in Azure Monitor link to open up the Azure Monitor dashboard in the Azure Portal as shown below, allowing you to drill down into various metrics or establish dashboards to monitor trends of interest.</p> <p></p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#2-deploy-embedding-model","title":"2. Deploy Embedding Model","text":"<p>The previous steps focused on the chat completion model which has many choices for us to select from. Now, let's look at embeddings. </p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#21-select-deploy-model","title":"2.1. Select &amp; Deploy Model","text":"<p>Start by setting the Inference Task to Embeddings. </p> <p>You'll find there are only about 11 models that match this filter - setting the Collection to Azure OpenAI reduces this further to 5. As before, let's select a model and review the card to see if it matches our needs. </p> <p>Then Confirm to get the Deployment wizard dialog.</p> <p></p> <p>And Deploy to complete the workflow.</p> <p></p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#23-verify-deployment","title":"2.3. Verify Deployment","text":"<p>Similarly, we can use the deployment card to view deployment details and explore metrics. But note that we don't have a Playground for embeddings.</p> <p></p>"},{"location":"1-Hybrid-Workshop/2-Setup/02/#3-deployment-complete","title":"3. Deployment Complete","text":"<p>The Azure AI Project overview page will now list both models under the <code>Models + endpoints</code> tab for easy lookup later (if you want to explore metrics or engage in Playground).</p> <p></p> <p>CONGRATULATIONS! You deployed both the AI models needed for RAG</p>"},{"location":"1-Hybrid-Workshop/2-Setup/03/","title":"2.3 Add Azure AI Search","text":"<p>The official tutorial recommends setting up an Azure AI Search resource at this stage. This was done under the assumption that the default Azure AI project setup did not create (new) or reuse (existing) Azure AI Search resources. </p> <p>However, since we opted to add Azure AI Search during project setup, we have nothing further to do at this stage! Note that the search resource is not yet populated with our data (search indexes). We'll get there in the Ideate section.</p> <p>CONGRATULATIONS! You completed setup of Azure AI Search indexes for your data</p>"},{"location":"1-Hybrid-Workshop/2-Setup/04/","title":"2.4 Add App Insights","text":""},{"location":"1-Hybrid-Workshop/2-Setup/04/#tracing-observability","title":"Tracing &amp; Observability","text":"<p>While not covered explicitly in the tutorial, we will be working with code in the Ideate section that is instrumented for observability (tracing). </p> <ul> <li>See: How to Trace your application with Azure AI Inference SDK</li> </ul> <p>In order to visualize those traces in the Azure AI Foundry Portal, we need to attach an Application Insights resource to our Azure AI project ahead of time. </p> <ul> <li>See: View your traces in Azure AI Foundry Portal</li> </ul>"},{"location":"1-Hybrid-Workshop/2-Setup/04/#create-new-app-insights","title":"Create New App Insights","text":"<p>Let's follow those steps (as illustrated in the animated gif below):</p> <ol> <li>Navigate to your Azure AI Project resource in the Azure AI Foundry portal</li> <li>Select the Tracing option in the menu sidebar </li> <li>Select Create New to attach a new Application Insights resource to the project</li> <li>Provide a name and select Create.</li> </ol> <p></p> <p>CONGRATULATIONS! You activated App Insights for tracing your Azure AI project</p>"},{"location":"1-Hybrid-Workshop/2-Setup/05/","title":"2.5 Setup Local Environment","text":"<p>The previous steps completed the setup of our Azure AI infrastructure (resources). Now it's time to setup our development environment to talk to our Azure backend.</p>"},{"location":"1-Hybrid-Workshop/2-Setup/05/#1-launch-github-codespaces","title":"1. Launch GitHub Codespaces","text":"<p>If you had not previously done so, complete the Getting Started steps now.</p> <ol> <li>Fork this repository to your personal GitHub profile.</li> <li>Open the fork in a new browser tab.</li> <li>Click on the blue \"Code\" button and select <code>Codespaces</code> </li> <li>Click on the <code>Create Codespaces on Main</code> button</li> </ol> <p>You should see GitHub Codespaces launch in a new browser tab. </p> <ul> <li>It will take a few minutes to complete loading. </li> <li>You should see a Visual Studio Code IDE in the browser</li> <li>When ready, you should see a VS Code terminal with active prompt.</li> </ul>"},{"location":"1-Hybrid-Workshop/2-Setup/05/#2-verify-azure-cli-installed","title":"2. Verify Azure CLI Installed","text":"<p>The repository is configured with a devcontainer that has all necessary dependencies pre-installed. Let's verify the <code>az</code> (Azure Developer CLI) was installed.</p> <pre><code>az version\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/05/#3-authenticate-with-azure-cli","title":"3. Authenticate with Azure CLI","text":"<p>Log into your Azure subscription from the VS Code terminal in GitHub Codespaces using the following command, and follow the prompts to complete the workflow.</p> <pre><code>az login --use-device-code\n</code></pre> <p>If you have a multi-tenancy account, you can set the default tenant when logging in as follows, where <code>&lt;TENANTID&gt;</code> is replaced with the relevant identifier.</p> <pre><code>az login --use-device-code --tenant &lt;TENANTID&gt;\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/05/#4-verify-python-packages","title":"4. Verify Python Packages","text":"<p>The codebase is set up with a <code>requirements.txt</code> file that has all the necesary Python package dependencies listed. These are auto-installed into the devcontainer at launch. Use <code>pip list | grep &lt;KEYWORD&gt;</code> to verify if specific packages were installed.</p> <p>For instance use this command to list <code>azure</code> packages installed and verify they match the ones listed in requirements (e.g., look for <code>azure-ai-projects</code>, <code>azure-ai-inference</code>, <code>azure-ai-identity</code>, <code>azure-search-documents</code>, <code>azure-core</code>, <code>azure-ai-evaluation</code>)</p> <pre><code>pip list | grep azure\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/06/","title":"2.6 Setup Project Structure","text":"<p>This repository contains the following structure to start with. The <code>*.sample</code> folders or files are there for reference only, so you can check your work.</p> <pre><code>data/            # Contains application data (initial)\ndocs/            # Contains docs and guides (content)\nsrc.sample/      # Sample src/ folder\n.env.sample       # Sample .env file\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/06/#1-define-src-folder-for-code","title":"1. Define <code>src/</code> folder for code","text":"<p>In this workshop, start by creating a new <code>src/</code> folder and populating it from scratch to get a sense for the development workflow. Start by creating this folder structure:</p> <pre><code>mkdir src/ src/api src/api/assets\n</code></pre> <p>Your directory structure should now look like this:</p> <pre><code>data/\ndocs/\nsrc.sample/\n.env.sample\nsrc/\nsrc/api\nsrc/api/assets\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/06/#2-add-srcconfigpy-helper-script","title":"2. Add <code>src/config.py</code> helper script","text":"<p>For convenience, let's copy this from the sample location - then review the code to see what it does. Use this command at the root of the repo:</p> <pre><code>cp src.sample/api/config.py src/api/.\n</code></pre> <p>Expand the code below to get a sense of what this helper does.</p> <ol> <li>Sets the <code>ASSET_PATH</code> to the <code>assets/</code> folder in the same directory.</li> <li>Configures the app logger and enables telemetry logging (traces) for app.</li> </ol> Click to expand and view the helper script src/api/config.py<pre><code># ruff: noqa: ANN201, ANN001\nimport os\nimport sys\nimport pathlib\nimport logging\nfrom azure.identity import DefaultAzureCredential\nfrom azure.ai.projects import AIProjectClient\nfrom azure.ai.inference.tracing import AIInferenceInstrumentor\n\n# load environment variables from the .env file\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Set \"./assets\" as the path where assets are stored, resolving the absolute path:\nASSET_PATH = pathlib.Path(__file__).parent.resolve() / \"assets\"\n\n# Configure an root app logger that prints info level logs to stdout\nlogger = logging.getLogger(\"app\")\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stream=sys.stdout))\n\n\n# Returns a module-specific logger, inheriting from the root app logger\ndef get_logger(module_name):\n    return logging.getLogger(f\"app.{module_name}\")\n\n\n# Enable instrumentation and logging of telemetry to the project\ndef enable_telemetry(log_to_project: bool = False):\n    AIInferenceInstrumentor().instrument()\n\n    # enable logging message contents\n    os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n\n    if log_to_project:\n        from azure.monitor.opentelemetry import configure_azure_monitor\n\n        project = AIProjectClient.from_connection_string(\n            conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n        )\n        tracing_link = f\"https://ai.azure.com/tracing?wsid=/subscriptions/{project.scope['subscription_id']}/resourceGroups/{project.scope['resource_group_name']}/providers/Microsoft.MachineLearningServices/workspaces/{project.scope['project_name']}\"\n        application_insights_connection_string = project.telemetry.get_connection_string()\n        if not application_insights_connection_string:\n            logger.warning(\n                \"No application insights configured, telemetry will not be logged to project. Add application insights at:\"\n            )\n            logger.warning(tracing_link)\n\n            return\n\n        configure_azure_monitor(connection_string=application_insights_connection_string)\n        logger.info(\"Enabled telemetry logging to project, view traces at:\")\n        logger.info(tracing_link)\n</code></pre> <p>CONGRATULATIONS! Your development environment is ready to use.</p>"},{"location":"1-Hybrid-Workshop/2-Setup/07/","title":"2.7 Configure Env Variables","text":"<p>We are now ready to start coding the chat AI application in our local development environment. But to do this, we need to configure a few environment variables.</p>"},{"location":"1-Hybrid-Workshop/2-Setup/07/#1-create-env-file","title":"1. Create <code>.env</code> file","text":"<ol> <li>Start by copying the <code>.env.sample</code> file to <code>.env</code></li> </ol> <pre><code>cp .env.sample .env\n</code></pre> <ol> <li>Let's review what this contains</li> </ol> <pre><code>cat .env\n</code></pre> <p>You will see something like this:</p> <pre><code>AIPROJECT_CONNECTION_STRING=&lt;your-connection-string&gt;\nAISEARCH_INDEX_NAME=\"contoso-products\"\nEMBEDDINGS_MODEL=\"text-embedding-ada-002\"\nINTENT_MAPPING_MODEL=\"gpt-4o-mini\"\nCHAT_MODEL=\"gpt-4o-mini\"\nEVALUATION_MODEL=\"gpt-4o-mini\"\n</code></pre>"},{"location":"1-Hybrid-Workshop/2-Setup/07/#2-update-connection-string","title":"2. Update Connection String","text":"<p>Note that defaults are provided for everything except the <code>AIPROJECT_CONNECTION_STRING</code> - let's fix that now!</p> <ol> <li> <p>Open the Azure AI Project overview page. It should look like this:</p> <p></p> </li> <li> <p>Look for the Project connection string under the Project details tab. </p> </li> <li>Copy that into <code>.env</code> as the AIPROJECT_CONNECTION_STRING value.</li> <li>Save the changes to <code>.env</code></li> </ol>"},{"location":"1-Hybrid-Workshop/2-Setup/07/#3-review-environment-variables","title":"3. Review Environment Variables","text":"<p>Let's review our environment variables:</p> <ol> <li><code>AIPROJECT_CONNECTION_STRING</code> - is a single connection URI that allows access to all the Connected Resources in the Azure AI project (including Azure AI Search).</li> <li><code>AISEARCH_INDEX_NAME</code> - is set to <code>contoso-products</code> and represents the index name that we will create and populate with product catalog data.</li> <li><code>EMBEDDINGS_MODEL</code> - the deployed model we'll use for vectorizing queries (see: Ideate 3.2)</li> <li><code>INTENT_MAPPING_MODEL</code> - the deployed model we'll use for intent mapping (see: Ideate 3.4)</li> <li><code>CHAT_MODEL</code> - the deployed model we'll use for final chat response (see: Ideate 3.6)</li> <li><code>EVALUATION_MODEL</code> - the deployed model we'll use for quality evaluation (see: Evaluate 4.3)</li> </ol> <p>CONGRATULATIONS! Your local environment is configured for code!</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/01/","title":"3.1 Add Application Data","text":"<p>This is Part 2 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY SDK.</p> <p>At the end of this section, you should have created an Azure AI Search index based on the retailer's product data, written and tested scripts to retrieve relevant product documents based on a user query, and implemented a chat AI that uses this knowledge as grounding context for a chat completion model. You will also get your first look at observability support with tracing.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/01/#1-add-productscsv-to-assets","title":"1. Add <code>products.csv</code> to <code>assets/</code>","text":"<p>We want to ground chat AI responses in our application data. In this case, we want to respond to customer queries about our products by grounding the responses in items found in our catalog.</p> <p>HOMEWORK: Think of other retail data sources that might be useful (and how to add them)</p> <p>Recall that the <code>src/config.py</code> script identifies the <code>assets/</code> folder as the source for all static assets. We already created the <code>src/api/assets</code> earlier.  Let's copy in the product catalog data into this folder now.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/products.csv  src/api/assets/\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/01/#2-inspect-productscsv-data","title":"2. Inspect <code>products.csv</code> data","text":"<p>Let's take a quick look at what this file contains in terms of product catalog data.</p> <ol> <li>We have 20 product records listed in CSV format.</li> <li>Each product has an id, name, price, category, brand, and text description</li> <li>The product description provides the most content about the product</li> <li>The product name is a unique title for that product.</li> </ol> Click to expand and view the Product Catalog data products.csv<pre><code>id,name,price,category,brand,description\n1,TrailMaster X4 Tent,250.0,Tents,OutdoorLiving,\"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\"\n2,Adventurer Pro Backpack,90.0,Backpacks,HikeMate,\"Venture into the wilderness with the HikeMate's Adventurer Pro Backpack! Uniquely designed with ergonomic comfort in mind, this backpack ensures a steadfast journey no matter the mileage. It boasts a generous 40L capacity wrapped up in durable nylon fabric ensuring its long-lasting performance on even the most rugged pursuits. It's meticulously fashioned with multiple compartments and pockets for organized storage, hydration system compatibility, and adjustable padded shoulder straps all in a lightweight construction. The added features of a sternum strap and hip belt enhance stability without compromising on comfort. The Adventurer Pro Backpack also prioritizes your safety with its reflective accents for when night falls. This buoyant beauty does more than carry your essentials; it carries the promise of a stress-free adventure!\"\n3,Summit Breeze Jacket,120.0,Hiking Clothing,MountainStyle,\"Discover the joy of hiking with MountainStyle's Summit Breeze Jacket. This lightweight jacket is your perfect companion for outdoor adventures. Sporting a trail-ready, windproof design and a water-resistant fabric, it's ready to withstand any weather. The breathable polyester material and adjustable cuffs keep you comfortable, whether you're ascending a mountain or strolling through a park. And its sleek black color adds style to function. The jacket features a full-zip front closure, adjustable hood, and secure zippered pockets. Experience the comfort of its inner lining and the convenience of its packable design. Crafted for night trekkers too, the jacket has reflective accents for enhanced visibility. Rugged yet chic, the Summit Breeze Jacket is more than a hiking essential, it's the gear that inspires you to reach new heights. Choose adventure, choose the Summit Breeze Jacket.\"\n4,TrekReady Hiking Boots,140.0,Hiking Footwear,TrekReady,\"Introducing the TrekReady Hiking Boots - stepping up your hiking game, one footprint at a time! Crafted from leather, these stylistic Trailmates are made to last. TrekReady infuses durability with its reinforced stitching and toe protection, making sure your journey is never stopped short. Comfort? They have that covered too! The boots are a haven with their breathable materials, cushioned insole, with padded collar and tongue; all nestled neatly within their lightweight design. As they say, it's what's inside that counts - so inside you'll find a moisture-wicking lining that quarantines stank and keeps your feet fresh as that mountaintop breeze. Remember the fear of slippery surfaces? With these boots, you can finally tell it to 'take a hike'! Their shock-absorbing midsoles and excellent traction capabilities promise stability at your every step. Beautifully finished in a traditional lace-up system, every adventurer deserves a pair of TrekReady Hiking Boots. Hike more, worry less!\"\n5,BaseCamp Folding Table,60.0,Camping Tables,CampBuddy,\"CampBuddy's BaseCamp Folding Table is an adventurer's best friend. Lightweight yet powerful, the table is a testament to fun-meets-function and will elevate any outing to new heights. Crafted from resilient, rust-resistant aluminum, the table boasts a generously sized 48 x 24 inches tabletop, perfect for meal times, games and more. The foldable design is a godsend for on-the-go explorers. Adjustable legs rise to the occasion to conquer uneven terrains and offer height versatility, while the built-in handle simplifies transportation. Additional features like non-slip feet, integrated cup holders and mesh pockets add a pinch of finesse. Quick to set up without the need for extra tools, this table is a silent yet indispensable sidekick during camping, picnics, and other outdoor events. Don't miss out on the opportunity to take your outdoor experiences to a new level with the BaseCamp Folding Table. Get yours today and embark on new adventures tomorrow! \"\n6,EcoFire Camping Stove,80.0,Camping Stoves,EcoFire,\"Introducing EcoFire's Camping Stove, your ultimate companion for every outdoor adventure! This portable wonder is precision-engineered with a lightweight and compact design, perfect for capturing that spirit of wanderlust. Made from high-quality stainless steel, it promises durability and steadfast performance. This stove is not only fuel-efficient but also offers an easy, intuitive operation that ensures hassle-free cooking. Plus, it's flexible, accommodating a variety of cooking methods whether you're boiling, grilling, or simmering under the starry sky. Its stable construction, quick setup, and adjustable flame control make cooking a breeze, while safety features protect you from any potential mishaps. And did we mention it also includes an effective wind protector and a carry case for easy transportation? But that's not all! The EcoFire Camping Stove is eco-friendly, designed to minimize environmental impact. So get ready to enhance your camping experience and enjoy delicious outdoor feasts with this unique, versatile stove!\"\n7,CozyNights Sleeping Bag,100.0,Sleeping Bags,CozyNights,\"Embrace the great outdoors in any season with the lightweight CozyNights Sleeping Bag! This durable three-season bag is superbly designed to give hikers, campers, and backpackers comfort and warmth during spring, summer, and fall. With a compact design that folds down into a convenient stuff sack, you can whisk it away on any adventure without a hitch. The sleeping bag takes comfort seriously, featuring a handy hood, ample room and padding, and a reliable temperature rating. Crafted from high-quality polyester, it ensures long-lasting use and can even be zipped together with another bag for shared comfort. Whether you're gazing at stars or catching a quick nap between trails, the CozyNights Sleeping Bag makes it a treat. Don't just sleep\u2014 dream with CozyNights.\"\n8,Alpine Explorer Tent,350.0,Tents,AlpineGear,\"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\"\n9,SummitClimber Backpack,120.0,Backpacks,HikeMate,\"Adventure waits for no one! Introducing the HikeMate SummitClimber Backpack, your reliable partner for every exhilarating journey. With a generous 60-liter capacity and multiple compartments and pockets, packing is a breeze. Every feature points to comfort and convenience; the ergonomic design and adjustable hip belt ensure a pleasantly personalized fit, while padded shoulder straps protect you from the burden of carrying. Venturing into wet weather? Fear not! The integrated rain cover has your back, literally. Stay hydrated thanks to the backpack's hydration system compatibility. Travelling during twilight? Reflective accents keep you visible in low-light conditions. The SummitClimber Backpack isn't merely a carrier; it's a wearable base camp constructed from ruggedly durable nylon and thoughtfully designed for the great outdoors adventurer, promising to withstand tough conditions and provide years of service. So, set off on that quest - the wild beckons! The SummitClimber Backpack - your hearty companion on every expedition!\"\n10,TrailBlaze Hiking Pants,75.0,Hiking Clothing,MountainStyle,\"Meet the TrailBlaze Hiking Pants from MountainStyle, the stylish khaki champions of the trails. These are not just pants; they're your passport to outdoor adventure. Crafted from high-quality nylon fabric, these dapper troopers are lightweight and fast-drying, with a water-resistant armor that laughs off light rain. Their breathable design whisks away sweat while their articulated knees grant you the flexibility of a mountain goat. Zippered pockets guard your essentials, making them a hiker's best ally. Designed with durability for all your trekking trials, these pants come with a comfortable, ergonomic fit that will make you forget you're wearing them. Sneak a peek, and you are sure to be tempted by the sleek allure that is the TrailBlaze Hiking Pants. Your outdoors wardrobe wouldn't be quite complete without them.\"\n11,TrailWalker Hiking Shoes,110.0,Hiking Footwear,TrekReady,\"Meet the TrekReady TrailWalker Hiking Shoes, the ideal companion for all your outdoor adventures. Constructed with synthetic leather and breathable mesh, these shoes are tough as nails yet surprisingly airy. Their cushioned insoles offer fabulous comfort for long hikes, while the supportive midsoles and traction outsoles with multidirectional lugs ensure stability and excellent grip. A quick-lace system, padded collar and tongue, and reflective accents make these shoes a dream to wear. From combating rough terrain with the reinforced toe cap and heel, to keeping off trail debris with the protective mudguard, the TrailWalker Hiking Shoes have you covered. These waterproof warriors are made to endure all weather conditions. But they're not just about being rugged, they're light as a feather too, minimizing fatigue during epic hikes. Each pair can be customized for a perfect fit with removable insoles and availability in multiple sizes and widths. Navigate hikes comfortably and confidently with the TrailWalker Hiking Shoes. Adventure, here you come!\"\n12,TrekMaster Camping Chair,50.0,Camping Tables,CampBuddy,\"Gravitate towards comfort with the TrekMaster Camping Chair from CampBuddy. This trusty outdoor companion boasts sturdy construction using high-quality materials that promise durability and enjoyment for seasons to come. Impeccably lightweight and portable, it's designed to be your go-to seat whether you're camping, at a picnic, cheering at a sporting event, or simply relishing in your backyard pleasures. Beyond its foldable design ensuring compact storage and easy transportation, its ergonomic magic is in the details. An adjustable recline, padded seat and backrest, integrated cup holder, and side pockets ensure the greatest outdoor comfort. Weather resistant, easy to clean, and capable of supporting diverse body types, this versatile chair also comes with a carry bag, ready for your next adventure.\"\n13,PowerBurner Camping Stove,100.0,Camping Stoves,PowerBurner,\"Unleash your inner explorer with the PowerBurner Dual Burner Camping Stove. It's designed for the adventurous heart, with sturdy construction and a high heat output that makes boiling and cooking a breeze. This stove isn't just about strength\u2014it's got finesse too. With adjustable flame control, you can simmer, saut\u00e9, or sizzle with absolute precision. Its compact design and integrated carrying handle make transportation effortless. Moreover, it's crafted to defy the elements, boasting a wind-resistant exterior and piezo ignition system for quick, reliable starts. And when the cooking's done, its removable grates make cleanup swift and easy. Rugged, versatile and reliable, the PowerBurner marks a perfect blend of practicality and performance. So, why wait? Let's turn up the heat on your outdoor culinary adventures today.\"\n14,MountainDream Sleeping Bag,130.0,Sleeping Bags,MountainDream,\"Meet the MountainDream Sleeping Bag: your new must-have companion for every outdoor adventure. Designed to handle 3-season camping with ease, it comes equipped with a premium synthetic insulation that will keep you cozy even when temperatures fall down to 15\u00b0F! Sporting a durable water-resistant nylon shell and soft breathable polyester lining, this bag doesn't sacrifice comfort for toughness. The star of the show is the contoured mummy shape that not only provides optimal heat retention but also cuts down on the weight. A smooth, snag-free YKK zipper with a unique anti-snag design allows for hassle-free operation, while the adjustable hood and full-length zipper baffle work together to ensure you stay warm all night long. Need to bring along some essentials? Not to worry! There's an interior pocket just for that. And when it's time to pack up? Just slip it into the included compression sack for easy storage and transport. Whether you're a backpacking pro or a camping novice, the MountainDream Sleeping Bag is the perfect blend of durability, warmth, and comfort that you've been looking for.\"\n15,SkyView 2-Person Tent,200.0,Tents,OutdoorLiving,\"Introducing the OutdoorLiving SkyView 2-Person Tent, a perfect companion for your camping and hiking adventures. This tent offers a spacious interior that houses two people comfortably, with room to spare. Crafted from durable waterproof materials to shield you from the elements, it is the fortress you need in the wild. Setup is a breeze thanks to its intuitive design and color-coded poles, while two large doors allow for easy access. Stay organized with interior pockets, and store additional gear in its two vestibules. The tent also features mesh panels for effective ventilation, and it comes with a rainfly for extra weather protection. Light enough for on-the-go adventurers, it packs compactly into a carrying bag for seamless transportation. Reflective guy lines ensure visibility at night for added safety, and the tent stands freely for versatile placement. Experience the reliability of double-stitched seams that guarantee increased durability, and rest easy under the stars with OutdoorLiving's SkyView 2-Person Tent. It's not just a tent; it's your home away from home.\"\n16,TrailLite Daypack,60.0,Backpacks,HikeMate,\"Step up your hiking game with HikeMate's TrailLite Daypack. Built for comfort and efficiency, this lightweight and durable backpack offers a spacious main compartment, multiple pockets, and organization-friendly features all in one sleek package. The adjustable shoulder straps and padded back panel ensure optimal comfort during those long exhilarating treks. Course through nature without worry as the daypack's water-resistant fabric protects your essentials from unexpected showers. Plus, never run dry with the integrated hydration system. And did we mention it comes in a plethora of colors and designs? So you can choose one that truly speaks to your outdoorsy soul! Keeping your visibility in mind, we've added reflective accents that light up in low-light conditions. Don't just carry a backpack, adorn a companion that takes you a step ahead in your adventures. Trust the TrailLite Daypack for a hassle-free, enjoyable hiking experience.\"\n17,RainGuard Hiking Jacket,110.0,Hiking Clothing,MountainStyle,\"Introducing the MountainStyle RainGuard Hiking Jacket - the ultimate solution for weatherproof comfort during your outdoor undertakings! Designed with waterproof, breathable fabric, this jacket promises an outdoor experience that's as dry as it is comfortable. The rugged construction assures durability, while the adjustable hood provides a customizable fit against wind and rain. Featuring multiple pockets for safe, convenient storage and adjustable cuffs and hem, you can tailor the jacket to suit your needs on-the-go. And, don't worry about overheating during intense activities - it's equipped with ventilation zippers for increased airflow. Reflective details ensure visibility even during low-light conditions, making it perfect for evening treks. With its lightweight, packable design, carrying it inside your backpack requires minimal effort. With options for men and women, the RainGuard Hiking Jacket is perfect for hiking, camping, trekking and countless other outdoor adventures. Don't let the weather stand in your way - embrace the outdoors with MountainStyle RainGuard Hiking Jacket!\"\n18,TrekStar Hiking Sandals,70.0,Hiking Footwear,TrekReady,\"Meet the TrekStar Hiking Sandals from TrekReady - the ultimate trail companion for your feet. Designed for comfort and durability, these lightweight sandals are perfect for those who prefer to see the world from a hiking trail. They feature adjustable straps for a snug, secure fit, perfect for adapting to the contours of your feet. With a breathable design, your feet will stay cool and dry, escaping the discomfort of sweaty hiking boots on long summer treks. The deep tread rubber outsole ensures excellent traction on any terrain, while the cushioned footbed promises enhanced comfort with every step. For those wild and unpredictable trails, the added toe protection and shock-absorbing midsole protect your feet from rocky surprises. Ingeniously, the removable insole makes for easy cleaning and maintenance, extending the lifespan of your sandals. Available in various sizes and a handsome brown color, the versatile TrekStar Hiking Sandals are just as comfortable on a casual walk in the park as they are navigating rocky slopes. Explore more with TrekReady!\"\n19,Adventure Dining Table,90.0,Camping Tables,CampBuddy,\"Discover the joy of outdoor adventures with the CampBuddy Adventure Dining Table. This feature-packed camping essential brings both comfort and convenience to your memorable trips. Made from high-quality aluminum, it promises long-lasting performance, weather resistance, and easy maintenance - all key for the great outdoors! It's light, portable, and comes with adjustable height settings to suit various seating arrangements and the spacious surface comfortably accommodates meals, drinks, and other essentials. The sturdy yet lightweight frame holds food, dishes, and utensils with ease. When it's time to pack up, it fold and stows away with no fuss, ready for the next adventure!  Perfect for camping, picnics, barbecues, and beach outings - its versatility shines as brightly as the summer sun! Durable, sturdy and a breeze to set up, the Adventure Dining Table will be a loyal companion on every trip. Embark on your next adventure and make lifetime memories with CampBuddy. As with all good experiences, it'll leave you wanting more! \"\n20,CompactCook Camping Stove,60.0,Camping Stoves,CompactCook,\"Step into the great outdoors with the CompactCook Camping Stove, a convenient, lightweight companion perfect for all your culinary camping needs. Boasting a robust design built for harsh environments, you can whip up meals anytime, anywhere. Its wind-resistant and fuel-versatile features coupled with an efficient cooking performance, ensures you won't have to worry about the elements or helpless taste buds while on adventures. The easy ignition technology and adjustable flame control make cooking as easy as a walk in the park, while its compact, foldable design makes packing a breeze. Whether you're camping with family or hiking solo, this reliable, portable stove is an essential addition to your gear. With its sturdy construction and safety-focused design, the CompactCook Camping Stove is a step above the rest, providing durability, quality, and peace of mind. Be wild, be free, be cooked for with the CompactCook Camping Stove!\"\n</code></pre>"},{"location":"1-Hybrid-Workshop/3-Ideate/02/","title":"3.2 Create Search Index","text":""},{"location":"1-Hybrid-Workshop/3-Ideate/02/#1-create-search-index-script","title":"1. Create Search Index Script","text":"<p>Let's copy over the <code>create-search-index.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/create-search-index.py  src/api/.\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/02/#2-understand-index-creation","title":"2. Understand Index Creation","text":"<p>Now, let's take a look at what this does.</p> Click to expand and view the Python Script to create the search index src/api/create-search-index.py<pre><code>    import os\n    from azure.ai.projects import AIProjectClient\n    from azure.ai.projects.models import ConnectionType\n    from azure.identity import DefaultAzureCredential\n    from azure.core.credentials import AzureKeyCredential\n    from azure.search.documents import SearchClient\n    from azure.search.documents.indexes import SearchIndexClient\n    from config import get_logger\n\n    # initialize logging object\n    logger = get_logger(__name__)\n\n    # create a project client using environment variables loaded from the .env file\n    project = AIProjectClient.from_connection_string(\n        conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n    )\n\n    # create a vector embeddings client that will be used to generate vector embeddings\n    embeddings = project.inference.get_embeddings_client()\n\n    # use the project client to get the default search connection\n    search_connection = project.connections.get_default(\n        connection_type=ConnectionType.AZURE_AI_SEARCH, include_credentials=True\n    )\n\n    # Create a search index client using the search connection\n    # This client will be used to create and delete search indexes\n    index_client = SearchIndexClient(\n        endpoint=search_connection.endpoint_url, credential=AzureKeyCredential(key=search_connection.key)\n    )\n</code></pre> <p>First the script sets up a search index_client:</p> <ol> <li>Creates an Azure AI Project Client instance (configured with connection string)</li> <li>Retrieves an <code>embeddings</code> inference client from the AI project (maps to that model)</li> <li>Retrieves a <code>search_connection</code> object from the AI project instance</li> <li>Creates an <code>index_client</code> search index client using the search connection (key, endpoint)</li> </ol> <p>First it  defines the index based on a vector derived from product data fields.</p> <ol> <li>It maps product name to a title property</li> <li>It maps product description to a content property</li> <li>It uses HNSW algorithm (cosine distance) for similarity</li> <li>It prioritizes \"content\" for semantic ranking</li> </ol> <p>It then creates the index from CSV and populates it using the index_client.</p> <ol> <li>It defines an index using the specified name and embeddings model</li> <li>It loads CSV and generates vector embeddings for each <code>description</code> </li> <li>It uploads each vectorized document into the pre-defined search index</li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/02/#3-run-index-creation-script","title":"3. Run Index Creation Script","text":"<p>To get the index created in Azure AI Search, </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python create-search-index.py\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/02/#4-verify-search-index","title":"4. Verify Search Index","text":"<p>Then verify that the index was created successfully:</p> <ol> <li>Visit the Azure Portal and look up your Resource Group</li> <li>Visit the Azure AI Search resource page from that RG</li> <li>Click on \"Search Explorer\" from the resource overview page</li> <li>Click \"Search\" - verify that you see indexed products</li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/03/","title":"3.3 Retrieve Related Products","text":""},{"location":"1-Hybrid-Workshop/3-Ideate/03/#1-add-docs-retrieval-script","title":"1. Add Docs Retrieval Script","text":"<p>Let's copy over the <code>get_product_documents.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/get_product_documents.py  src/api/.\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/03/#2-understand-docs-retrieval","title":"2. Understand Docs Retrieval","text":"<p>Let's start with a sample user query like this:</p> <pre><code> I need a new tent for 4 people, what would you recommend?\n</code></pre> <p>Different users could phrase the question in different ways, with different levels of information. But we need to map all these queries to a search query that works on the product database. How do we do that? We use a 3-step process:</p> <ol> <li>We teach an AI to extract user intent from an input text query</li> <li>We teach the AI  to map user intent to a search query on products</li> <li>We use the search index to retrieve product documents matching query.</li> </ol> <p>Let's see how we do this.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/03/#3-create-ai-project-client","title":"3. Create AI Project Client","text":"<ol> <li>Create an Azure AI Project client using the connection string</li> <li>Use the client to retrieve a <code>chat_completions</code> inference client</li> <li>Use the client to retrieve an <code>embeddings</code> inference client</li> <li>Use the client to setup a <code>search_client</code> using the search connection</li> </ol> Click to expand and view the Python script src/api/get_product_documents.py - Part 1<pre><code># ----------------------------------------------\n# 1. Create Search Index Client \n# ----------------------------------------------\nimport os\nfrom pathlib import Path\nfrom opentelemetry import trace\nfrom azure.ai.projects import AIProjectClient\nfrom azure.ai.projects.models import ConnectionType\nfrom azure.identity import DefaultAzureCredential\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient\nfrom config import ASSET_PATH, get_logger\n\n# initialize logging and tracing objects\nlogger = get_logger(__name__)\ntracer = trace.get_tracer(__name__)\n\n# create a project client using environment variables loaded from the .env file\nproject = AIProjectClient.from_connection_string(\n    conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n)\n\n# create a vector embeddings client that will be used to generate vector embeddings\nchat = project.inference.get_chat_completions_client()\nembeddings = project.inference.get_embeddings_client()\n\n# use the project client to get the default search connection\nsearch_connection = project.connections.get_default(\n    connection_type=ConnectionType.AZURE_AI_SEARCH, include_credentials=True\n)\n\n# Create a search index client using the search connection\n# This client will be used to create and delete search indexes\nsearch_client = SearchClient(\n    index_name=os.environ[\"AISEARCH_INDEX_NAME\"],\n    endpoint=search_connection.endpoint_url,\n    credential=AzureKeyCredential(key=search_connection.key),\n)\n</code></pre>"},{"location":"1-Hybrid-Workshop/3-Ideate/03/#4-get-docs-for-user-intent","title":"4. Get Docs For User Intent","text":"<ol> <li>First, receive input text string (user query)</li> <li>Then, map user query text into a clear intent (search query)</li> <li>Then, vectorize the search query (to support retrieval)</li> <li>Then, search the product index for matches (by cosine similarity)</li> <li>Then, for each matching product, retrieve its document (content)</li> <li>Return the collection of documents to the user.</li> </ol> Click to expand and view the Python script src/api/get_product_documents.py - Part 2<pre><code>    # ----------------------------------------------\n    # 2. Define Function to Get Product Documents\n    # ----------------------------------------------\n    from azure.ai.inference.prompts import PromptTemplate\n    from azure.search.documents.models import VectorizedQuery\n\n    @tracer.start_as_current_span(name=\"get_product_documents\")\n    def get_product_documents(messages: list, context: dict = None) -&gt; dict:\n        if context is None:\n            context = {}\n\n        overrides = context.get(\"overrides\", {})\n        top = overrides.get(\"top\", 5)\n\n        # generate a search query from the chat messages\n        intent_prompty = PromptTemplate.from_prompty(Path(ASSET_PATH) / \"intent_mapping.prompty\")\n\n        intent_mapping_response = chat.complete(\n            model=os.environ[\"INTENT_MAPPING_MODEL\"],\n            messages=intent_prompty.create_messages(conversation=messages),\n            **intent_prompty.parameters,\n        )\n\n        # the search_query returned here will be a stringified JSON object\n        search_query = intent_mapping_response.choices[0].message.content\n        logger.debug(f\"\ud83e\udde0 Intent mapping: {search_query}\")\n\n        # -- OLD: generate a vector representation of the search query\n        # embedding = embeddings.embed(model=os.environ[\"EMBEDDINGS_MODEL\"], input=search_query)\n\n        # --- NEW: generate a vector representation of the search query\n        #  The intent mapping response is a stringied JSON object \n        #   with the intent and search_query components. We need to\n        #   extract the search_query term and create embedding from it\n        import json\n        intent_map = json.loads(search_query)\n        embedding = embeddings.embed(model=os.environ[\"EMBEDDINGS_MODEL\"], input=intent_map[\"search_query\"])\n        search_vector = embedding.data[0].embedding\n        # --- END\n\n        # search the index for products matching the search query\n        vector_query = VectorizedQuery(vector=search_vector, k_nearest_neighbors=top, fields=\"contentVector\")\n\n        search_results = search_client.search(\n            search_text=search_query, vector_queries=[vector_query], select=[\"id\", \"content\", \"filepath\", \"title\", \"url\"]\n        )\n\n        documents = [\n            {\n                \"id\": result[\"id\"],\n                \"content\": result[\"content\"],\n                \"filepath\": result[\"filepath\"],\n                \"title\": result[\"title\"],\n                \"url\": result[\"url\"],\n            }\n            for result in search_results\n        ]\n\n        # add results to the provided context\n        if \"thoughts\" not in context:\n            context[\"thoughts\"] = []\n\n        # add thoughts and documents to the context object so it can be returned to the caller\n        context[\"thoughts\"].append(\n            {\n                \"title\": \"Generated search query\",\n                \"description\": search_query,\n            }\n        )\n\n        if \"grounding_data\" not in context:\n            context[\"grounding_data\"] = []\n        context[\"grounding_data\"].append(documents)\n\n        logger.debug(f\"\ud83d\udcc4 {len(documents)} documents retrieved: {documents}\")\n        return documents\n</code></pre>"},{"location":"1-Hybrid-Workshop/3-Ideate/03/#5-run-docs-retrieval-script","title":"5. Run Docs Retrieval Script","text":"<p>Before we can run this script, we need to create the Intent Mapper template for step 2. Let's do that next.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/04/","title":"3.4 Understand Intent Mapping","text":""},{"location":"1-Hybrid-Workshop/3-Ideate/04/#1-add-intent-mapping-prompty","title":"1. Add Intent Mapping Prompty","text":"<p>Let's copy over the <code>intent_mapping.prompty</code> prompt template into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/intent_mapping.prompty src/api/assets/.\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/04/#2-run-docs-retrieval-script","title":"2. Run Docs Retrieval Script","text":"<p>Before we dive into the details of that file, let's first run the document retrieval script and see what happens. Here's an example with the question we discussed earlier.</p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python get_product_documents.py --query \"I need a new tent for 4 people, what would you recommend?\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83e\udde0 Intent mapping: {\n    \"intent\": \"The user is looking for recommendations for a tent suitable for 4 people.\",\n    \"search_query\": \"best tents for 4 people\"\n}\n</code></pre> </li> </ol> <p>The script output shows that it extracted the user intent and formulated a search query from it that related to a product (\"best tents for 4 people\") - and can be answered by the search index.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/04/#3-intent-mapping-in-action","title":"3. Intent Mapping In Action","text":"<p>The intent mapping is achieved using a Prompty asset - a YAML file that consists of frontmatter (prompt metdata) and content (prompt template)</p> <ul> <li>Frontmatter defines model configuration and prompt inputs</li> <li>Template defines prompt structure, context and instructions</li> </ul> <p>Looking into the details of the prompt template, we can see it employs a few-shot learning technique where it attempts to teach the AI to execute a specific task (extract intent) by providing it with examples of inputs and expected responses.</p> Click to expand and view Intent Mapping Prompty src/api/assets/intent_mapping.prompty<pre><code> ---\nname: Chat Prompt\ndescription: A prompty that extract users query intent based on the current_query and chat_history of the conversation\nmodel:\n    api: chat\n    configuration:\n        azure_deployment: gpt-4o\ninputs:\n    conversation:\n        type: array\n---\nsystem:\n# Instructions\n- You are an AI assistant reading a current user query and chat_history.\n- Given the chat_history, and current user's query, infer the user's intent expressed in the current user query.\n- Once you infer the intent, respond with a search query that can be used to retrieve relevant documents for the current user's query based on the intent\n- Be specific in what the user is asking about, but disregard parts of the chat history that are not relevant to the user's intent.\n- Provide responses in json format\n\n# Examples\nExample 1:\nWith a conversation like below:\n    ```\n    - user: are the trailwalker shoes waterproof?\n    - assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They are designed with a durable and waterproof construction to withstand various terrains and weather conditions.\n    - user: how much do they cost?\n    ```\nRespond with:\n{\n    \"intent\": \"The user wants to know how much the Trailwalker Hiking Shoes cost.\",\n    \"search_query\": \"price of Trailwalker Hiking Shoes\"\n}\n\nExample 2:\nWith a conversation like below:\n    ```\n    - user: are the trailwalker shoes waterproof?\n    - assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They are designed with a durable and waterproof construction to withstand various terrains and weather conditions.\n    - user: how much do they cost?\n    - assistant: The TrailWalker Hiking Shoes are priced at $110.\n    - user: do you have waterproof tents?\n    - assistant: Yes, we have waterproof tents available. Can you please provide more information about the type or size of tent you are looking for?\n    - user: which is your most waterproof tent?\n    - assistant: Our most waterproof tent is the Alpine Explorer Tent. It is designed with a waterproof material and has a rainfly with a waterproof rating of 3000mm. This tent provides reliable protection against rain and moisture.\n    - user: how much does it cost?\n    ```\nRespond with:\n{\n    \"intent\": \"The user would like to know how much the Alpine Explorer Tent costs.\",\n    \"search_query\": \"price of Alpine Explorer Tent\"\n}\n\nuser:\nReturn the search query for the messages in the following conversation:\n{{#conversation}}\n- {{role}}: {{content}}\n{{/conversation}}\n</code></pre>"},{"location":"1-Hybrid-Workshop/3-Ideate/05/","title":"3.5 Create Augmented Query","text":""},{"location":"1-Hybrid-Workshop/3-Ideate/05/#1-add-chat-with-products-script","title":"1. Add Chat With Products Script","text":"<p>Let's copy over the <code>chat_with_products.py</code> script into our application source.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/chat_with_products.py src/api/.\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/05/#2-understand-rag-workflow","title":"2. Understand RAG Workflow","text":"<p>This script is the core orchestrator for our RAG workflow, executing the following steps:</p> <ol> <li>Create an Azure AI Project client (with connection string)</li> <li>Retrieve the inference client for chat completions model</li> <li>Use incoming user messages to retrieve related products</li> <li>Use this knowledge to populate a grounded chat template</li> <li>Call the chat completions client with this prompt template</li> </ol> Click to expand and view Chat With Products script (segment) src/api/chat_with_products.py<pre><code>from azure.ai.inference.prompts import PromptTemplate\n\n\n@tracer.start_as_current_span(name=\"chat_with_products\")\ndef chat_with_products(messages: list, context: dict = None) -&gt; dict:\n    if context is None:\n        context = {}\n\n    documents = get_product_documents(messages, context)\n\n    # do a grounded chat call using the search results\n    grounded_chat_prompt = PromptTemplate.from_prompty(Path(ASSET_PATH) / \"grounded_chat.prompty\")\n\n    system_message = grounded_chat_prompt.create_messages(documents=documents, context=context)\n    response = chat.complete(\n        model=os.environ[\"CHAT_MODEL\"],\n        messages=system_message + messages,\n        **grounded_chat_prompt.parameters,\n    )\n    logger.info(f\"\ud83d\udcac Response: {response.choices[0].message}\")\n\n    # Return a chat protocol compliant response\n    return {\"message\": response.choices[0].message, \"context\": context}\n</code></pre> <p>In the next section, we'll look at the prompt template and run a test with a sample query.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/05/#3-run-chat-with-products-script","title":"3. Run Chat With Products Script","text":"<p>Before we can run this script, we need to create the Grounded Chat Prompt template for step 4. Let's do that next.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/06/","title":"3.6 Design Grounded Prompt","text":""},{"location":"1-Hybrid-Workshop/3-Ideate/06/#1-add-grounded-chat-prompty","title":"1. Add Grounded Chat Prompty","text":"<p>Let's copy over the <code>grounded_chat.prompty</code> prompt template into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li> <p>Then run this command:</p> <pre><code>cp src.sample/api/assets/grounded_chat.prompty src/api/assets/.\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/06/#2-understand-grounding-context","title":"2. Understand Grounding Context","text":"<p>Explore the contents of this template. Notice how the <code>system</code> context provides clear instructions and guidance to ensure quality responses. This includes grounding responses in context (when query is relevant) and declining to provide responses (when query is irrelevant).</p> Click to expand and view Grounded Chat Prompty src/api/assets/grounded_chat.prompty<pre><code>    ---\n    name: Chat with documents\n    description: Uses a chat completions model to respond to queries grounded in relevant documents\n    model:\n        api: chat\n        configuration:\n            azure_deployment: gpt-4o\n    inputs:\n        conversation:\n            type: array\n    ---\n    system:\n    You are an AI assistant helping users with queries related to outdoor outdooor/camping gear and clothing.\n    If the question is not related to outdoor/camping gear and clothing, just say 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?'\n    Don't try to make up any answers.\n    If the question is related to outdoor/camping gear and clothing but vague, ask for clarifying questions instead of referencing documents. If the question is general, for example it uses \"it\" or \"they\", ask the user to specify what product they are asking about.\n    Use the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, correctly, and concisely as possible.\n    Do not add documentation reference in the response.\n\n    # Documents\n\n    {{#documents}}\n\n    ## Document {{id}}: {{title}}\n    {{content}}\n    {{/documents}}\n</code></pre>"},{"location":"1-Hybrid-Workshop/3-Ideate/06/#3-chat-with-products-relevant","title":"3. Chat With Products - Relevant","text":"<p>Run the script with a test query (from the <code>src/api</code> folder). </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> <pre><code>python chat_with_products.py --query \"I need a new tent for 4 people, what would you recommend?\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83d\udcac Response: {'content': \"I recommend the TrailMaster X4 Tent. It is specifically designed to accommodate four occupants comfortably. The tent features durable water-resistant construction, multiple doors for easy access, and mesh panels for ventilation and bug protection. Additionally, it has a freestanding design for easy setup and relocation, as well as interior pockets for organization. It's a great choice for your camping adventures!\", 'role': 'assistant'}\n</code></pre> </li> </ol> <p>Is the response grounded in product data from the catalog? </p>"},{"location":"1-Hybrid-Workshop/3-Ideate/06/#4-chat-with-products-irrelevant","title":"4. Chat With Products - Irrelevant","text":"<p>Try asking a question that does not relate to the hiking and camping topic:</p> <ol> <li> <p>Verify you are still in the <code>src/api</code> folder. </p> </li> <li> <p>Then run this script:</p> <pre><code>python chat_with_products.py --query \"I am looking for a recipe for spicy bean burgers\"\n</code></pre> </li> <li> <p>Observe the response. It may look like this:</p> <pre><code>\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n</code></pre> </li> </ol> <p>Is this response relevant and grounded in the context for this application? </p>"},{"location":"1-Hybrid-Workshop/3-Ideate/07/","title":"3.7 Test with Observability","text":"<p>Recall that we activated Application Insights during the setup phase of our project. This now allows to ask questions with telemetry enabled and get observable traces using open telemetry, to help us analyze the cost or performance of our workflows.</p> <p>Let's see this in action.</p>"},{"location":"1-Hybrid-Workshop/3-Ideate/07/#1-enable-telemetry-on-test","title":"1. Enable Telemetry on Test","text":"<ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script: Run the <code>Chat with Products</code> script with <code>--enable-telemetry</code> as shown.</p> <pre><code>python chat_with_products.py --query \"I need hiking gear for a trip to Andalusia - what tents and boots do you recommend?\" --enable-telemetry\n</code></pre> </li> <li> <p>You should see something like this in the console. Let's explore this next.</p> <pre><code>Enabled telemetry logging to project, view traces at:\nhttps://ai.azure.com/tracing?wsid=/subscriptions/XXXX/resourceGroups/ninarasi-ragchat-rg/providers/Microsoft.MachineLearningServices/workspaces/ninarasi-ragchat-v1\n\ud83d\udcac Response: {'content': \"For your trip to Andalusia, I recommend the following tents and boots:\\n\\n**Tents:**\\n1. **Alpine Explorer Tent**: This robust, 8-person, 3-season tent is perfect for group camping. It has multiple mesh windows for ventilation and a detachable divider for privacy. Its waterproof feature ensures you stay dry during unexpected rain.\\n\\n2. **SkyView 2-Person Tent**: If you're looking for a smaller option, this tent comfortably houses two people and is made from durable waterproof materials. It also features an intuitive setup system, effective ventilation, and a rainfly for extra weather protection, making it great for hiking and camping.\\n\\n**Boots:**\\n1. **TrekReady Hiking Boots**: These boots are crafted from leather, ensuring durability and comfort on long hikes. They have a moisture-wicking lining, shock-absorbing midsoles, and excellent traction, making them suitable for various terrains.\\n\\n2. **TrekStar Hiking Sandals**: If you prefer something lighter and more breathable, consider these lightweight sandals. They offer adjustable straps, excellent traction, toe protection, and a cushioned footbed for comfort during summer treks.\\n\\nChoose based on your group size and hiking preferences, and you'll be well-prepared for your adventure in Andalusia!\", 'role': 'assistant'}\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/3-Ideate/07/#2-view-traces-detail","title":"2. View Traces Detail","text":"<p>Look for the output section with a link as shown below, and navigate to that URL in the browser.</p> <pre><code>Enabled telemetry logging to project, view traces at:\nhttps://ai.azure.com/tracing?....\n</code></pre> <p>It will take a few minutes for the traces to show up. Refresh periodically to see results.</p> <p>You should see something like this reflecting the latest run of the Chat with Products script above. Click to expand the tree of nodes on the left and observe the details provided in the panel on the right, as you step through them.</p> <ol> <li>We can trace the flow of control from the user query to the returned response</li> <li>We can measure the time taken for each step to execute (in seconds)</li> <li>We can observe the cost for model invocations (in tokens) in the GenAI rows</li> <li>For a given model interaction, we can explore details (system, user, assistant) to debug</li> </ol> <p></p>"},{"location":"1-Hybrid-Workshop/3-Ideate/07/#3-view-traces-dashboard","title":"3. View Traces Dashboard","text":"<p>Click on the Tracing menu option in the sidebar to get the historical logs from previous runs. This is an effective way to analyze issues in cost or performance, make changes, then compare trace runs to see if the iterations had any impact.</p> <p></p>"},{"location":"1-Hybrid-Workshop/3-Ideate/07/#4-view-traces-insights","title":"4. View Traces Insights","text":"<p>You can also click on the <code>Insights for Generative AI Applications Dashboard</code> link (top of screen) to get a more actionable Generative AI Application Insights (Preview) dashboard for real-time insights and analysis of usage patterns.</p> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/01/","title":"4.1 Create Evaluation Dataset","text":"<p>This begins Part 3 of the tutorial. This stage is completed USING THE AZURE AI FOUNDRY SDK.</p> <p>At the end of this section, you should have established an evaluation inputs dataset, created an evaluation script for AI-assisted evaluation, and run the script to assess the chat AI app for quality. You will then learn to explore the evaluation outcomes locally, and via the Azure AI Foundry portal, and understand how to customize and automate the process for rapid iteration and improvement of your application quality.</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/01/#1-evaluating-generative-ai-apps","title":"1. Evaluating Generative AI Apps","text":"<p>The evaluation phase is critical to assessing the quality and safety of your generative AI application. The Azure AI Foundry provides a comprehensive set of tools and guidance to support evaluation in three dimensions. Learn More Here.</p> <p></p> <ol> <li>Risk and safety evaluators: Evaluating potential risks associated with AI-generated content. Ex: evaluating AI predisposition towards generating harmful or inappropriate content.</li> <li>Performance and quality evaluators: Assessing accuracy, groundedness, and relevance of generated content using robust AI-assisted and Natural Language Processing (NLP) metrics.</li> <li>Custom evaluators: Tailored evaluation metrics that allow for more detailed and specific analyses. Ex: addressing app-specific requirements not covered by standard metrics.</li> </ol> <p>AI-Assisted Evaluators are available only in select regions (Recommended: East US 2)</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/01/#2-ai-assisted-evaluation-flow","title":"2. AI-Assisted Evaluation Flow","text":"<p>So far, we've tested the chat application interactively (command-line) using a single test prompt. Now, we want to evaluate the responses on a larger and more diverse set of test prompts including edge cases. We can then use those results to iterate on our application (e.g., prompt template, data sources) till evaluations pass our acceptance criteria.</p> <p>To do this we use AI-Assisted Evaluation - also referred to as LLM-as-a-judge - where we ask a second AI model (\"judge\") to grade the responses of the first AI model (\"target\"). The workflow is as shown below:</p> <ol> <li>First, create an evaluation dataset that consists of diverse queries for testing.</li> <li>Next, have the target AI (app) generate responses for each query</li> <li>Next, have the judge AI (assessor) grade tge {query, response} pairs </li> <li>Finally, visualize results (individual vs. aggregate metrics) for review.</li> </ol> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/01/#3-create-evaluation-dataset","title":"3. Create Evaluation Dataset","text":"<p>Let's copy over the <code>chat_eval_data.jsonl</code> dataset into our assets folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li>Then run this command:</li> </ol> <pre><code>cp src.sample/api/assets/chat_eval_data.jsonl src/api/assets/.\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/01/#4-review-evaluation-dataset","title":"4. Review Evaluation Dataset","text":"<p>The Azure AI Foundry supports different data formats for evaluation including:</p> <ol> <li>Query/Response - each result has the query, response, and ground truth.</li> <li>Conversation (single/multi-turn) - messages (with content, role, optional context)</li> </ol> Click to expand and view the evaluation dataset src/api/assets/chat_eval_data.jsonl<pre><code>{\"query\": \"Which tent is the most waterproof?\", \"truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\"}\n{\"query\": \"Which camping table holds the most weight?\", \"truth\": \"The Adventure Dining Table has a higher weight capacity than all of the other camping tables mentioned\"}\n{\"query\": \"How much do the TrailWalker Hiking Shoes cost? \", \"truth\": \"The Trailewalker Hiking Shoes are priced at $110\"}\n{\"query\": \"What is the proper care for trailwalker hiking shoes? \", \"truth\": \"After each use, remove any dirt or debris by brushing or wiping the shoes with a damp cloth.\"}\n{\"query\": \"What brand is TrailMaster tent? \", \"truth\": \"OutdoorLiving\"}\n{\"query\": \"How do I carry the TrailMaster tent around? \", \"truth\": \" Carry bag included for convenient storage and transportation\"}\n{\"query\": \"What is the floor area for Floor Area? \", \"truth\": \"80 square feet\"}\n{\"query\": \"What is the material for TrailBlaze Hiking Pants?\", \"truth\": \"Made of high-quality nylon fabric\"}\n{\"query\": \"What color does TrailBlaze Hiking Pants come in?\", \"truth\": \"Khaki\"}\n{\"query\": \"Can the warrenty for TrailBlaze pants be transfered? \", \"truth\": \"The warranty is non-transferable and applies only to the original purchaser of the TrailBlaze Hiking Pants. It is valid only when the product is purchased from an authorized retailer.\"}\n{\"query\": \"How long are the TrailBlaze pants under warranty for? \", \"truth\": \" The TrailBlaze Hiking Pants are backed by a 1-year limited warranty from the date of purchase.\"}\n{\"query\": \"What is the material for PowerBurner Camping Stove? \", \"truth\": \"Stainless Steel\"}\n{\"query\": \"Is France in Europe?\", \"truth\": \"Sorry, I can only queries related to outdoor/camping gear and equipment\"}\n</code></pre> <p>Our dataset reflects the first format, where the test prompts contain a query with the ground truth for evaluating responses. The chat AI will then generate a response (based on query) that gets added to this record, to create the evaluation dataset that is sent to the \"judge\" AI.</p> <p><pre><code> {\n    \"query\": \"Which tent is the most waterproof?\", \n    \"truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\"\n}\n</code></pre> Let's look at the evaluation script that orchestrates this workflow, next</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/","title":"4.2 Create Evaluation Script","text":""},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#1-create-evaluation-script","title":"1. Create Evaluation Script","text":"<p>Let's copy over the <code>evaluate.py</code> script into our application source folder.</p> <ol> <li>Make sure you are in the root directory of the repo.</li> <li>Then run this command:</li> </ol> <pre><code>cp src.sample/api/evaluate.py  src/api/.\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#2-review-evaluation-workflow","title":"2. Review Evaluation Workflow","text":"<p>Let's review the workflow required for AI-Assisted evaluation:</p> <ol> <li>We have an evaluation test dataset containing query/truth pairs</li> <li>We have a target AI (applicationl) that will generate the responses</li> <li>We have a judge AI (evaluator) that will grade those responses</li> <li>The judge has scoring criteria they use to generate evaluation metrics</li> <li>The evaluation results are published locally, or to Azure AI Foundry</li> </ol> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#3-unpack-evaluation-script","title":"3. Unpack Evaluation Script","text":""},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#31-create-ai-project-client","title":"3.1 Create AI Project Client","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 1. Create AI Project Client \n    # ----------------------------------------------\n    import os\n    import pandas as pd\n    from azure.ai.projects import AIProjectClient\n    from azure.ai.projects.models import ConnectionType\n    from azure.ai.evaluation import evaluate, GroundednessEvaluator\n    from azure.identity import DefaultAzureCredential\n\n    from chat_with_products import chat_with_products\n\n    # load environment variables from the .env file at the root of this repo\n    from dotenv import load_dotenv\n    load_dotenv()\n\n    # create a project client using environment variables loaded from the .env file\n    project = AIProjectClient.from_connection_string(\n        conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"], credential=DefaultAzureCredential()\n    )\n\n    connection = project.connections.get_default(connection_type=ConnectionType.AZURE_OPEN_AI, include_credentials=True)\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#32-specify-model-evaluators","title":"3.2 Specify Model &amp; Evaluators","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 2. Define Evaluator Model to use\n    # ----------------------------------------------\n    evaluator_model = {\n        \"azure_endpoint\": connection.endpoint_url,\n        \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n        \"api_version\": \"2024-06-01\",\n        \"api_key\": connection.key,\n    }\n\n    groundedness = GroundednessEvaluator(evaluator_model)\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#33-create-evaluation-wrapper","title":"3.3 Create Evaluation Wrapper","text":"src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 3. Create Eval Wrapper Function for Query\n    # ----------------------------------------------\n    def evaluate_chat_with_products(query):\n        response = chat_with_products(messages=[{\"role\": \"user\", \"content\": query}])\n        return {\"response\": response[\"message\"].content, \"context\": response[\"context\"][\"grounding_data\"]}\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/02/#34-run-evaluation-print","title":"3.4 Run Evaluation &amp; Print","text":"<p>This is the entry point for the evaluation script. </p> <ul> <li>It uses the evaluate function from the <code>azure.ai.evaluation</code> package to run a built-in evaluator (GroundednessEvaluator) to score the responses from the target app.</li> <li>If both the data (test) and target (function) are provided, it will first invoke the target with that data - and then run evaluations on the results.</li> <li>If <code>azure_ai_project</code> is set, then the evaluation results are also logged to Azure AI Foundry</li> </ul> src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 4. Run the Evaluation\n    #    View Results Locally (Saved as JSON)\n    #    Get Link to View Results in Foundry Portal\n    #    NOTE:\n    #    Evaluation takes more tokens \n    #    Try to increase Rwate limit (Tokens per minute)\n    #    Script should handle limit errors if needed\n    # ----------------------------------------------\n    # Evaluate must be called inside of __main__, not on import\n\n    if __name__ == \"__main__\":\n        from config import ASSET_PATH\n\n        # workaround for multiprocessing issue on linux\n        from pprint import pprint\n        from pathlib import Path\n        import multiprocessing\n        import contextlib\n\n        with contextlib.suppress(RuntimeError):\n            multiprocessing.set_start_method(\"spawn\", force=True)\n\n        # run evaluation with a dataset and target function, \n        # log to the project\n        result = evaluate(\n            data=Path(ASSET_PATH) / \"chat_eval_data.jsonl\",\n            target=evaluate_chat_with_products,\n            evaluation_name=\"evaluate_chat_with_products\",\n            evaluators={\n                \"groundedness\": groundedness,\n            },\n            evaluator_config={\n                \"default\": {\n                    \"query\": {\"${data.query}\"},\n                    \"response\": {\"${target.response}\"},\n                    \"context\": {\"${target.context}\"},\n                }\n            },\n            azure_ai_project=project.scope,\n            output_path=\"./myevalresults.json\",\n        )\n\n        tabular_result = pd.DataFrame(result.get(\"rows\"))\n\n        pprint(\"-----Summarized Metrics-----\")\n        pprint(result[\"metrics\"])\n        pprint(\"-----Tabular Result-----\")\n        pprint(tabular_result)\n        pprint(f\"View evaluation results in AI Studio: {result['studio_url']}\")\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/03/","title":"4.3 Configure Evaluation Model","text":"<p>Recall that in the last section, the evaluation script identified an evaluator_model that will serve as the judge AI for this assessment. </p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/03/#1-specifying-evaluator-model","title":"1. Specifying Evaluator Model","text":"<p>In this workshop, we are reusing the same model for both chat_completion and evaluation roles, but you can choose to separate the two by:</p> <ul> <li>Deploying a new model to the same Azure AI Project</li> <li>Updating the <code>EVALUATION_MODEL</code> environment variable to this one</li> <li>Restarting the evaluation script</li> </ul> <p>HOMEWORK: Try deploying a <code>gpt-4</code> model for evaluations. How do results differ?</p> src/api/evaluate.py<pre><code>    # ----------------------------------------------\n    # 2. Define Evaluator Model to use\n    # ----------------------------------------------\n    evaluator_model = {\n        \"azure_endpoint\": connection.endpoint_url,\n        \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n        \"api_version\": \"2024-06-01\",\n        \"api_key\": connection.key,\n    }\n\n    groundedness = GroundednessEvaluator(evaluator_model)\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/03/#2-configuring-evaluator-model","title":"2. Configuring Evaluator Model","text":"<p>Let's take a look at the core <code>evaluate</code> function that executes the workflow. This function will run an assessment once for each record (in <code>data</code>), for each evaluator (in <code>evaluators</code>). This requires a lot of calls to the identified evaluation model - which will require a higher token capacity for efficient completion.</p> <p>Note: The current script uses a single evaluator (for Groundedness). Adding additional evaluators will increase the number of calls made to the default model, so make sure you configure quota to adjust for that accordingly.=</p> <p>Update the model quota in Azure AI Foundry if execution has rate limit issues</p> <p>Take these steps to view and update your model quota.</p> <ul> <li>Visit your Azure AI project page in Azure AI Foundry</li> <li>Click \"Models + Endpoints\" and select the evaluation model</li> <li>Click <code>Edit</code> and increase the Tokens per minute rate limit* (e.g., to 30)</li> <li>Click <code>Save and close</code> </li> </ul> Click to expand and see a screenshot of the update dialog <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/04/","title":"4.4 Run Evaluation Script","text":"<p>To run the evaluation script from the Visual Studio Code terminal:</p> <ul> <li>You need to be authenticated on Azure</li> <li>You need to have the <code>azure-ai-evaluation</code> package installed</li> </ul> <p>You should have done the first step at the start of this workshop. The dev container has package installed already.</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/04/#1-run-the-script","title":"1. Run the Script","text":"<p>Run the script from the <code>src/api</code> folder). </p> <ol> <li> <p>Change to the <code>src/api</code> folder </p> <pre><code>cd src/api\n</code></pre> </li> <li> <p>Run the script:</p> </li> </ol> <pre><code>python evaluate.py\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/04/#2-observe-the-output","title":"2. Observe the Output","text":"<ul> <li>Note that there are 13 response records corresponding to the 13 test inputs in our evaluation dataset. These reflect the first stage of evaluation flow where the target AI (chat app) is creating a responses file based on the test inputs given.</li> <li>Note that you can view the traces in local device at the URL provided. This will launch a local version of the trace viewer.</li> </ul> <pre><code>Starting prompt flow service...\nStart prompt flow service on 127.0.0.1:23333, version: 1.16.2.\nYou can stop the prompt flow service with the following command:'pf service stop'.\n\nYou can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780\n[2024-12-16 16:37:42 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780, log path: /home/vscode/.promptflow/.runs/main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780/logs.txt\n\ud83d\udcac Response: {'content': 'Could you please specify which camping table you are referring to? There are multiple options available, and I can provide information on them.', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': \"Could you specify what aspect of care you're asking about? Are you looking for cleaning instructions, storage tips, or something else for the TrailWalker Hiking Shoes?\", 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': \"Could you please specify which tents you are comparing, or do you want information about a specific tent's waterproof features?\", 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'The TrailBlaze Hiking Pants are crafted from high-quality nylon fabric.', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'The TrailMaster X4 Tent comes with an included carry bag, which makes transporting the tent easy and convenient. You can simply pack the tent into the carry bag and carry it as needed for your camping adventure. If you have any more specific questions about the tent or its features, feel free to ask!', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n\ud83d\udcac Response: {'content': 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?', 'role': 'assistant'}\n...\n...\n...\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/04/#3-rate-limit-errors","title":"3. Rate Limit Errors","text":"<p>Occasionally you might see an error message that looks like this. This relates to the tokens per minute rate limits on your evaluation model deployment. The script is designed to handle them and continue running - reconfiguring the model can help.</p> <pre><code>[2024-12-16 16:44:07 +0000][promptflow.core._prompty_utils][ERROR] - Exception occurs: RateLimitError: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-06-01 have exceeded token rate limit of your current AIServices S0 pricing tier. Please retry after 60 seconds. Please contact Azure support service if you would like to further increase the default rate limit.'}}\n[2024-12-16 16:44:07 +0000][promptflow.core._prompty_utils][WARNING] - RateLimitError #2, Retry-After=60, Back off 60.0 seconds for retry.\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/04/#4-final-result","title":"4. Final Result","text":"<p>Once the evaluation workflow completes, you should see a run summary that looks like this. Note that the evaluation results are saved locally, and also published to the Azure AI Foundry portal.</p> <pre><code>======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\nRun status: \"Completed\"\nStart time: \"2024-12-16 16:42:05.695977+00:00\"\nDuration: \"0:03:06.490785\"\nOutput path: \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\n\n======= Combined Run Summary (Per Evaluator) =======\n\n{\n    \"groundedness\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:03:06.490785\",\n        \"completed_lines\": 13,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/vscode/.promptflow/.runs/azure_ai_evaluation_evaluators_common_base_eval_asyncevaluatorbase_rvrjml8t_20241216_164205_696721\"\n    }\n}\n\n====================================================\n\nEvaluation results saved to \"/workspaces/learns-azure-ai-foundry/src/api/myevalresults.json\".\n\n'-----Summarized Metrics-----'\n{'groundedness.gpt_groundedness': 1.4615384615384615,\n'groundedness.groundedness': 1.4615384615384615}\n'-----Tabular Result-----'\n                                    outputs.response  ... line_number\n0   Could you please specify which tents you are c...  ...           0\n1   Could you please specify which camping table y...  ...           1\n2   Sorry, I only can answer queries related to ou...  ...           2\n3   Could you specify what aspect of care you're a...  ...           3\n4   Sorry, I only can answer queries related to ou...  ...           4\n5   The TrailMaster X4 Tent comes with an included...  ...           5\n6   Sorry, I only can answer queries related to ou...  ...           6\n7   The TrailBlaze Hiking Pants are crafted from h...  ...           7\n8   Sorry, I only can answer queries related to ou...  ...           8\n9   Sorry, I only can answer queries related to ou...  ...           9\n10  Sorry, I only can answer queries related to ou...  ...          10\n11  Sorry, I only can answer queries related to ou...  ...          11\n12  Sorry, I only can answer queries related to ou...  ...          12\n\n[13 rows x 8 columns]\n('View evaluation results in AI Studio: '\n'https://ai.azure.com/build/evaluation/XXXXXXX?wsid=/subscriptions/XXXXXXXX/resourceGroups/ninarasi-ragchat-rg/providers/Microsoft.MachineLearningServices/workspaces/ninarasi-ragchat-v1')\n'''\n\n# ----------------------------------------------\n</code></pre>"},{"location":"1-Hybrid-Workshop/4-Evaluate/05/","title":"4.5 View Results Locally","text":"<p>In the previous section, we noticed that the console provided a truncated summary of the results of the evaluation run. But what if you wanted to see the details or observe the traces for these runs? You have two options - local or Azure AI Foundry portal.</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/05/#1-view-traces-locally","title":"1. View Traces Locally","text":"<p>The console log from the execution run will show you a trace viewer link URL:</p> <pre><code>You can view the traces in local from http://127.0.0.1:23333/v1.0/ui/traces/?#run=main_evaluate_chat_with_products_rxna_3r9_20241216_163719_733780\n</code></pre> <p>Navigate to that link in your browser, and you should get a trace viewer landing page that looks like this, with Traces and Collections.</p> <p></p> <p>If Traces stays on status Running, try switching to Collections and back to force a Refresh.</p> <p>Click on Traces - you should now be able to see records for the trace runs for each invocation of the chat application, with timestamps for each run.</p> <p></p> <p>Click on any row in the table to get the detailed trace view for that run - where you can drive into the call stack to understand the time taken for each call, the tokens consumer, and the inputs and outputs from each processing step.</p> <p>COMPARE IT: Contrast the local trace view to the Azure Foundry Portal view  seen earlier. How are they different?</p> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/05/#2-view-results-locally","title":"2. View Results Locally","text":"<p>The evaluation run provides us a summary of results in the console, but it is truncated and hard to analyze. However, observe that the results are also stored in a local JSON file that you can open up in the Visual Studio Code IDE for exploration.</p> <p>Check out the <code>src.sample/api/myevalresults.json</code> for a sample file showing the outputs from a previous run. The snippet below reproduces one of the rows from those results - let's see what that provides:</p> <ol> <li>The <code>inputs.query</code> and <code>inputs.truth</code> are from the test input file</li> <li>The <code>outputs.context</code> reflects retrieved product documents used (RAG)</li> <li>The <code>outputs.response</code> gives the target models returned response</li> <li>The <code>outputs.groundedness.groundedness</code> has a rating of 1 (not grounded)</li> <li>The <code>outputs.groundedness.groundedness_reaason</code> explains why (context unused)</li> </ol> <p>Note: While the response is not grounded in the context, it does in fact reflect our prompt template guidance to ask for clarifications on questions where the intent is not clear.</p> <p>Click to expand a view a sample row from <code>myevalresults.json</code></p> <pre><code>    {\n        \"outputs.response\": \"Could you please specify which tents you are comparing, or do you want information about a specific tent's waterproof features?\",\n        \"outputs.context\": [\n            [\n                {\n                    \"id\": \"8\",\n                    \"content\": \"Welcome to the joy of camping with the Alpine Explorer Tent! This robust, 8-person, 3-season marvel is from the responsible hands of the AlpineGear brand. Promising an enviable setup that is as straightforward as counting sheep, your camping experience is transformed into a breezy pastime. Looking for privacy? The detachable divider provides separate spaces at a moment's notice. Love a tent that breathes? The numerous mesh windows and adjustable vents fend off any condensation dragon trying to dampen your adventure fun. The waterproof assurance keeps you worry-free during unexpected rain dances. With a built-in gear loft to stash away your outdoor essentials, the Alpine Explorer Tent emerges as a smooth balance of privacy, comfort, and convenience. Simply put, this tent isn't just a shelter - it's your second home in the heart of nature! Whether you're a seasoned camper or a nature-loving novice, this tent makes exploring the outdoors a joyous journey.\",\n                    \"filepath\": \"alpine-explorer-tent\",\n                    \"title\": \"Alpine Explorer Tent\",\n                    \"url\": \"/products/alpine-explorer-tent\"\n                },\n                {\n                    \"id\": \"15\",\n                    \"content\": \"Introducing the OutdoorLiving SkyView 2-Person Tent, a perfect companion for your camping and hiking adventures. This tent offers a spacious interior that houses two people comfortably, with room to spare. Crafted from durable waterproof materials to shield you from the elements, it is the fortress you need in the wild. Setup is a breeze thanks to its intuitive design and color-coded poles, while two large doors allow for easy access. Stay organized with interior pockets, and store additional gear in its two vestibules. The tent also features mesh panels for effective ventilation, and it comes with a rainfly for extra weather protection. Light enough for on-the-go adventurers, it packs compactly into a carrying bag for seamless transportation. Reflective guy lines ensure visibility at night for added safety, and the tent stands freely for versatile placement. Experience the reliability of double-stitched seams that guarantee increased durability, and rest easy under the stars with OutdoorLiving's SkyView 2-Person Tent. It's not just a tent; it's your home away from home.\",\n                    \"filepath\": \"skyview-2-person-tent\",\n                    \"title\": \"SkyView 2-Person Tent\",\n                    \"url\": \"/products/skyview-2-person-tent\"\n                },\n                {\n                    \"id\": \"1\",\n                    \"content\": \"Unveiling the TrailMaster X4 Tent from OutdoorLiving, your home away from home for your next camping adventure. Crafted from durable polyester, this tent boasts a spacious interior perfect for four occupants. It ensures your dryness under drizzly skies thanks to its water-resistant construction, and the accompanying rainfly adds an extra layer of weather protection. It offers refreshing airflow and bug defence, courtesy of its mesh panels. Accessibility is not an issue with its multiple doors and interior pockets that keep small items tidy. Reflective guy lines grant better visibility at night, and the freestanding design simplifies setup and relocation. With the included carry bag, transporting this convenient abode becomes a breeze. Be it an overnight getaway or a week-long nature escapade, the TrailMaster X4 Tent provides comfort, convenience, and concord with the great outdoors. Comes with a two-year limited warranty to ensure customer satisfaction.\",\n                    \"filepath\": \"trailmaster-x4-tent\",\n                    \"title\": \"TrailMaster X4 Tent\",\n                    \"url\": \"/products/trailmaster-x4-tent\"\n                },\n                {\n                    \"id\": \"14\",\n                    \"content\": \"Meet the MountainDream Sleeping Bag: your new must-have companion for every outdoor adventure. Designed to handle 3-season camping with ease, it comes equipped with a premium synthetic insulation that will keep you cozy even when temperatures fall down to 15\\u00b0F! Sporting a durable water-resistant nylon shell and soft breathable polyester lining, this bag doesn't sacrifice comfort for toughness. The star of the show is the contoured mummy shape that not only provides optimal heat retention but also cuts down on the weight. A smooth, snag-free YKK zipper with a unique anti-snag design allows for hassle-free operation, while the adjustable hood and full-length zipper baffle work together to ensure you stay warm all night long. Need to bring along some essentials? Not to worry! There's an interior pocket just for that. And when it's time to pack up? Just slip it into the included compression sack for easy storage and transport. Whether you're a backpacking pro or a camping novice, the MountainDream Sleeping Bag is the perfect blend of durability, warmth, and comfort that you've been looking for.\",\n                    \"filepath\": \"mountaindream-sleeping-bag\",\n                    \"title\": \"MountainDream Sleeping Bag\",\n                    \"url\": \"/products/mountaindream-sleeping-bag\"\n                },\n                {\n                    \"id\": \"9\",\n                    \"content\": \"Adventure waits for no one! Introducing the HikeMate SummitClimber Backpack, your reliable partner for every exhilarating journey. With a generous 60-liter capacity and multiple compartments and pockets, packing is a breeze. Every feature points to comfort and convenience; the ergonomic design and adjustable hip belt ensure a pleasantly personalized fit, while padded shoulder straps protect you from the burden of carrying. Venturing into wet weather? Fear not! The integrated rain cover has your back, literally. Stay hydrated thanks to the backpack's hydration system compatibility. Travelling during twilight? Reflective accents keep you visible in low-light conditions. The SummitClimber Backpack isn't merely a carrier; it's a wearable base camp constructed from ruggedly durable nylon and thoughtfully designed for the great outdoors adventurer, promising to withstand tough conditions and provide years of service. So, set off on that quest - the wild beckons! The SummitClimber Backpack - your hearty companion on every expedition!\",\n                    \"filepath\": \"summitclimber-backpack\",\n                    \"title\": \"SummitClimber Backpack\",\n                    \"url\": \"/products/summitclimber-backpack\"\n                }\n            ]\n        ],\n        \"inputs.query\": \"Which tent is the most waterproof?\",\n        \"inputs.truth\": \"The Alpine Explorer Tent has the highest rainfly waterproof rating at 3000m\",\n        \"outputs.groundedness.groundedness\": 1,\n        \"outputs.groundedness.gpt_groundedness\": 1,\n        \"outputs.groundedness.groundedness_reason\": \"The RESPONSE does not reference any of the tents or their features from the CONTEXT, making it completely ungrounded. It fails to provide any relevant information or insights based on the provided material.\",\n        \"line_number\": 0\n    },\n</code></pre> <p>But local results are not persistent in a way that helps us compare or process data over long periods of time. This is where having the Evaluations output stored in Azure AI Foundry portal can help.</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/","title":"4.6 View Results In Portal","text":"<p>In the previous step, we looked at the traces and evaluation results in the local environment. However, we configured our evaluation script to also push the results to the Azure AI Foundry portal.  Let's take a look at how those results are visualized.</p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/#1-evaluations-tab-on-portal","title":"1. Evaluations Tab On Portal","text":"<p>Navigate to the Azure AI project page in Azure AI Portal, and select the Evaluation item on the sidebar. You should see an evaluations landing page like this, with the latest evaluation run listed in the table. The list entry shows the average Groundedness score for that run.</p> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/#2-evaluations-results-on-portal","title":"2. Evaluations Results On Portal","text":"<p>Click on the evaluations run in the list to get this detailed dashboard view:</p> <ul> <li>The Evaluation details section give overall status. Click the <code>raw JSON</code> link to dive deeper.</li> <li>The Metrics dashboard visualizes AI Quality metrics and supports Custom charts.</li> <li>The Detailed metrics result shows evaluation results in tabular form (with search &amp; filters)</li> </ul> <p>Use the metrics dashboard to get a visual understanding of how the metrics are distributed across the evaluation results. For instance, we can see that in our evaluation, 11 responses were considered ungrounded and 2 were given a groundedness score of 4. However, this does not give us insight into why those scores were given.</p> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/#3-explore-detailed-metrics","title":"3. Explore Detailed Metrics","text":"<p>This is where the detailed metrics help. We can browse through the results in tabular form, or we can drill down into the evaluations for a specific query or product using search. In this example, we see that the TrailMaster product was relevant to at least 3 of the 13 queries - but the scores ranged from 1 (low groundedness) to 4 (high groundedness).</p> <p></p> <p>However, with this view, we can drill down into the reasons for the score, and take follow up actions to improve it. For instance:</p> <ol> <li> <p>The first query received a low score of 1 because the response did not reference any of the tents in the provided context. But if we look deeper, we may notice that the response is actually reflecing the instructions provided in our system context - so in this case, the response was not grounded, but was relevant. </p> src/assets/grounded_chat.prompty<pre><code>system:\nYou are an AI assistant helping users with queries related to outdoor outdooor/camping gear and clothing.\nIf the question is not related to outdoor/camping gear and clothing, just say 'Sorry, I only can answer queries related to outdoor/camping gear and clothing. So, how can I help?'\nDon't try to make up any answers.\nIf the question is related to outdoor/camping gear and clothing but vague, ask for clarifying questions instead of referencing documents. If the question is general, for example it uses \"it\" or \"they\", ask the user to specify what product they are asking about.\nUse the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, correctly, and concisely as possible.\nDo not add documentation reference in the response.\n</code></pre> </li> <li> <p>The second query received a low score of 1 which appears justified again. In this case, we note that the response reflects instructions related to questions that are off-topic - so this may be a place to investigate =why the question is seen as off-topic despite mentioning a product in the list.</p> </li> <li> <p>The third query received a high score of 5 which again looks valid, given the reasoning of this being incomplete. However, if we look at the truth and compare it to the response, we may find that it meets our expectations - and lead us to refining the evaluation prompt that defines the scoring criteria.</p> </li> </ol>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/#4-build-custom-charts","title":"4. Build Custom Charts","text":"<p>One of the value propositions of using the Azure AI Foundry portal is the ability to create custom charts based on the evaluation results. Click the <code>Custom</code> tab and walk through the creation dialog to add visuals that reflect specific views into the data. For example, this view helps us see that a disproportionate number of responses were in the <code>Sorry, I only can answer queries related to ..</code> category, indicating that we may need to refine our chat prompt template guidance to ensure we are not rejecting valid queries.</p> <p></p>"},{"location":"1-Hybrid-Workshop/4-Evaluate/06/#5-try-more-evaluators","title":"5. Try More Evaluators","text":"<p>The Azure AI Foundry platform has an Evaluator library with an extensive list of built-in evaluators that cover risk &amp; safety, performance &amp; quality assessment. </p> <p></p> HOMEWORK: Try adding more evaluators to the script <p>To use a named evaluator - update the <code>evaluate.py</code> script to import the selected options as shown below.</p> <ol> <li> <p>Import the evaluators     <pre><code>from azure.ai.evaluation import F1ScoreEvaluator, RelevanceEvaluator, ViolenceEvaluator\n</code></pre></p> </li> <li> <p>Configure them with the chosen evaluation model</p> <pre><code>evaluator_model = {\n    \"azure_endpoint\": connection.endpoint_url,\n    \"azure_deployment\": os.environ[\"EVALUATION_MODEL\"],\n    \"api_version\": \"2024-06-01\",\n    \"api_key\": connection.key,\n}\nf1score = F1ScoreEvaluator(evaluator_model)\nrelevance = RelevanceScoreEvaluator(evaluator_model)\nviolence = ViolenceScoreEvaluator(evaluator_model)\n</code></pre> </li> <li> <p>Specify them in the call to the evaluate function</p> <pre><code>result = evaluate(\n    data=Path(ASSET_PATH) / \"chat_eval_data.jsonl\",\n    target=evaluate_chat_with_products,\n    evaluation_name=\"evaluate_chat_with_products\",\n    evaluators={\n        \"groundedness\": groundedness,\n    },\n    evaluator_config={\n        \"default\": {\n            \"query\": {\"${data.query}\"},\n            \"response\": {\"${target.response}\"},\n            \"context\": {\"${target.context}\"},\n        }\n    },\n    azure_ai_project=project.scope,\n    output_path=\"./myevalresults.json\",\n)\n</code></pre> </li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/","title":"5.1 Recap: Build A Copilot","text":"<p>CONGRATULATIONS! You just learn to use the Azure AI Foundry platform to build a RAG-based copilot</p>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#1-what-you-learned-today","title":"1. What You Learned Today","text":"<p>By completing the workshop, you gained three things:</p> <ol> <li>You have a working knowledge of how to build a RAG-based copilot.</li> <li>You have a working familiarity with the Azure AI Foundry platform.</li> <li>You have a functional sandbox in this repo, to experiment further.</li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#2-where-can-you-go-next","title":"2. Where Can You Go Next?","text":"<p>Take advantage of this repository and GitHub Codespaces environment to start exploring the Azure AI Platform portal, SDK and tooling, in more intentional ways.</p>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#21-setup","title":"2.1 Setup","text":"<ol> <li>The Azure AI Foundry Architecture</li> <li>Management Center</li> <li>Azure AI Foundry SDK</li> <li>How To: Create a project in Azure AI Foundry portal</li> <li>How To: Create and manage an Azure AI Foundry Hub</li> <li>How To: Deploy AI Models in Azure AI Foundry</li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#22-ideate","title":"2.2 Ideate","text":"<ol> <li>Quickstart: Use the Chat Playground</li> <li>Quickstart: Build a Chat App using Azure AI SDK</li> <li>Quickstart: Get Started Using Azure OpenAI Assistants</li> <li>Tutorial Build a custom chat app with the Azure AI Foundry SDK</li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#23-evaluate","title":"2.3 Evaluate","text":"<ol> <li>Evaluation of generative AI applications</li> <li>Evaluation and monitoring metrics for generative AI</li> <li>How To: Generate synthetic and simulated data for evaluation</li> <li>How To: Evaluate your Generative AI application with the Azure AI Evaluation SDK</li> <li>How To: Evaluate Generative AI models and applications with Azure AI Foundry Portal</li> <li>Tracing in Azure AI Inference SDK overview</li> <li>How To: Trace your application with Azure AI Inference SDK</li> <li>How To: Visualize your traces</li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/01/#24-deploy","title":"2.4 Deploy","text":"<ol> <li>Deploy an enterprise chat web app</li> <li>Azure AI App Templates</li> </ol>"},{"location":"1-Hybrid-Workshop/5-Evolve/02/","title":"5.2 Refactor: Make it Better","text":""},{"location":"1-Hybrid-Workshop/5-Evolve/02/#1-contoso-chat-sample","title":"1. Contoso Chat Sample","text":"<p>Once you've familiarized yourself with the basic setup, ideation and evaluation capabilities, you can explore the Contoso Chat sample for more advanced insights, on your own. </p> <p>This sample uses the same retail dataset used in this RAG Chat workshop, but streamlines the end-to-end development workflow with core developer tools like Azure Developer CLI, to automate provisioning and deployment. The sample also teaches you how to package up your application prototype and deploy it into production using Azure Container Apps.</p> <p>The Contoso Chat Workshop walks you through the end-to-end development journey from prompt to production, using an AI App template that can be provisioned and deployed with a single command (<code>azd up</code>). The sample also shows you how to use a FastAPI application server (to create an API endpoint for accepting requests to our chat AI) and how to package up the application as a Docker container that can be deployed to an Azure Container Apps endpoint for real-world interactions.</p> <p></p> <p>Contoso Chat is currently in v3. An updated v4 (Jan 2025) will reflect recent Azure AI SDK updates</p>"},{"location":"1-Hybrid-Workshop/5-Evolve/02/#2-rag-chat-sample-v2","title":"2. RAG Chat Sample (v2)","text":"<p>Another option is to use this existing repository and workshop as a sandbox sample that you can customize to your own requirements. Here are some suggestions for ways to experiment further:</p> <ol> <li> <p>Bring Your Own Data - Walk through the steps but replace the <code>product.csv</code> with your data, and understand the implications for all the other steps in the workflow. For example - you will need to create a new set of evaluation test inputs (for your use case) and refactor the prompt templates (for intent mapping and chat-with-products) to reflect new instructions or context.</p> </li> <li> <p>Integrate More Sources - The basic sample has a single data source (product catalog index). However, the <code>data/</code> folder provides additional data sources (customer data, product manual data) that can be used for even richer experiences. Think of how you can refactor the existing code to support data retrieval from multiple sources that store this data (e.g., Customer data in Azure Cosmos DB).</p> </li> <li> <p>Write Custom Evaluators - The default evaluators for quality reflect common best practices. However, you may want to assess responses for a custom criteria. Think of how you can write a custom evaluator, and add it into the evalution script. For example: evaluate responses for politeness or for being kid-friendly.</p> </li> <li> <p>Explore Richer RAG Patterns - The core of RAG patterns is the retrieval of relevant knowledge from various sources including Azure AI Search. Explore new algorithms or ways of combining context to make the retrieved documents more relevant to application needs.</p> </li> <li> <p>Make it Agentic - Agentic workflows are dominating the AI ecosystem today. Agentic RAG refers to the use of AI agents for information retrieval where the agent mediates between multiple data sources to drive enhanced RAG pipelines for delivery. Read more here.</p> </li> </ol>"},{"location":"1-Hybrid-Workshop/6-Cleanup/","title":"6. Cleanup \ud83d\udea8","text":"<p>We deployed AI models and an AI search resource. We used GitHub Codespaces for development. These can incur unnecessary costs or quota usage if left running. LET'S CLEAN THIS UP NEXT!</p>"},{"location":"1-Hybrid-Workshop/6-Cleanup/#1-delete-github-codespaces","title":"1. Delete GitHub Codespaces","text":"<p>Github Codespaces has a free tier for personal accounts with 15GB storage and 120 Core hours per month. This quota is more than sufficient for running this workshop, but leaving the Codespaces running  will use up that quota unnecessarily.</p> <p>Let's delete the active codespaces.</p> <ol> <li>Visit Your Codespaces page on GitHub.</li> <li>Scroll to see the Owned by [username] section. For example: the screenshot shows the section <code>Owned by nitya</code> listing my codespaces.</li> <li>Identify the GitHub Codespaces instance used for this workshop by checking the repo name shown above the codespaces name. For example: the screenshot shows <code>nitya/azure-ai-rag-workshop</code> as the repo for the <code>fluffy system</code> codespace.</li> </ol> <p></p> <p>The codespace may show unsaved changes (see: <code>main*</code> under codespaces name, where the <code>*</code> indicates you have unsaved changes on the main branch). You can commit these changes to save your workshop progress, or you can ignore them to retain the original workshop. </p> <p>Let's delete the codespace. Click the <code>...</code> icon to get the drop-down menu as shown below. You now have the option to Stop codespace or Delete it (last option in list). I recommend you Delete it since this is just a learning workshop. You can always start a new Codespace later.</p> <p>Congratulations! You deleted your GitHub Codespaces!</p>"},{"location":"1-Hybrid-Workshop/6-Cleanup/#2-delete-resource-group","title":"2. Delete Resource Group","text":"<p>The workshop would have resulted in the deployment of an Azure AI hub and project resource, along with supporting Azure AI services and resources like Azure AI Search, Azure OpenAI, and Application Insights. </p> <p>Let's delete these resources now</p> <ol> <li>Visit the Azure AI Foundry Portal and log in.</li> <li>Visit the Azure AI project page for this workshop.</li> <li>Click on the Management Center in sidebar (bottom, left)</li> <li>You should see something like this - click on the Resource Group link.     </li> <li>You should be redirected to the Azure Portal and see something like this:     </li> <li>Click the Delete resource group and complete the workflow.</li> <li>Deletion will take a few minutes to complete (watch the status bar).</li> <li>When completed, refresh screen to verify Resource Group was deleted.</li> </ol> <p>Congratulations! You deleted your Resource Group!</p>"},{"location":"1-Hybrid-Workshop/6-Cleanup/#3-purge-deleted-resources","title":"3. Purge Deleted Resources","text":"<p>When you delete an Azure AI services resource, you may encounter a soft delete issue where the resource is not completely purged by default. This can have two implications:</p> <ol> <li>Associated model quota is not released, affecting your ability to reuse it.</li> <li>You cannot create another resource with the same name for 48 hours.</li> </ol> <p>You can address these by manually purging deleted Azure AI services resources using the Azure portal, Azure CLI or Rest API options. Let's use the Azure Portal approach.</p> <ol> <li>Navigate to the Azure Portal and log in.</li> <li>You should see something like this. Click on the <code>Azure AI Services</code> icon.     </li> <li>You should see something like this. Click on the <code>Azure AI services</code> sidebar option.     </li> <li>You should see something like this. Click on the <code>Manage deleted resources</code> option in the menu to get the slideout panel seen at the right.     </li> <li>Make sure the subscription is set to the right one from the workshop. Any deleted resources that have not been purged will be listed here. You can then select and complete the workflow to release those resources for reuse. </li> </ol> <p>If the resource included model quota you can verify the quota was released by looking up the Management Center / Model quota tab in the Azure AI Foundry portal.</p> <p>Congratulations! You purged any soft-deleted Azure AI resources!</p> <p>Your cleanup is complete. \u2705</p>"},{"location":"2-Portal-First/1-Overview/00/","title":"1.1 Learning Roadmap","text":"<p>TThis workshop teaches you the capabilities of the Azure AI Foundry Portal with a set of interactive labs that take you from catalog (model selection) to cloud (application deployment). The labs are derived from the documentation but assembled into an end-to-end narrative for an AI Engineer journey.</p>"},{"location":"2-Portal-First/1-Overview/00/#1-core-objectives","title":"1. Core Objectives","text":"<p>This workshop has two core objectives:</p> <ul> <li>Develop familiarity with the layout and capabilities of the Azure AI Foundry Portal (web UI)</li> <li>Learn how to build, evaluate, and deploy, a RAG-based generative AI app portal-first.</li> </ul> <p>In this context, portal-first means that we prioritize using the Azure AI Foundry portal for the end-to-end developer workflow. By comprison, the Hybrid approach uses the Azure AI Foundry Portal (low-code) for setup and the Azure AI Foundry SDK (code-first) for ideation and evaluation.</p>"},{"location":"2-Portal-First/1-Overview/00/#2-learning-journey","title":"2. Learning Journey","text":"<p>By completing the labs in this workshop, you will learn to do the following:</p> <ol> <li>Model Selection - use the Azure AI model catalog to discover and compare models.</li> <li>Project Setup - create an Azure AI hub &amp; project with models and connected resources.</li> <li>Ideation - go from initial prompt to functional prototype using model (with &amp; without data).</li> <li>Evaluation - learn about built-in and custom evaluators, run an evaluation flow &amp; view results.</li> <li>Observability - learn about tracing and app insights, view run traces in the portal.</li> <li>Deployment - go from prototype to production by deploying an app and using the endpoint.</li> </ol> <p>Along the way, we'll also understand how to orchestrate complex workflows in the portal using the currently-provided tooling (prompt flow) and a retrieval-augmented generation pattern (RAG) to improve responses by grounding them in your data.</p> OPTIONAL \u2192 Once you've completed this exercise, try the Hybrid Workshop to get your first experience with the Azure AI Foundry SDK for a code-first development workflow in Python."},{"location":"2-Portal-First/1-Overview/01/","title":"1.2 Application Lifecycle","text":""},{"location":"2-Portal-First/1-Overview/01/#1-generative-ai-operations","title":"1. Generative AI Operations","text":"<p>When we think about the AI Engineer's journey from prompt to production, we also need to understand the paradigm shifts in Generative AI Operations based on the following challenges faced by customers:</p> <ul> <li>Complex Model Landscape - how can I select the right model for my use case?</li> <li>Data Quality &amp; Quantity - how can I discover or generate quality datasets for use?</li> <li>Operational Performance - how can I balance tokens, cost &amp; performance optimization?</li> <li>Security &amp; Compliance - how can I meet regulatory requirements &amp; deliver trustworthy AI?</li> </ul> <p>The result is a paradigm shift from traditional MLOps to LLMOps - and now GenAIOps - with focus on a comprehensive set of practives, tools, foundation models, and frameworks to intergrate people, processes and platforms. The Azure AI platform offers a robust suite of tools and services to support this end-to-end developer journey, as shown below.</p> <p></p> <p>Let's look at how we can go from prompt to production using a Portal-first approach where we prioritize usage of tools and processes in the browser-based UI for a low-code experience.</p>"},{"location":"2-Portal-First/1-Overview/01/#2-e2e-development-worflow","title":"2. E2E Development Worflow","text":"<p>To put the labs in context, let's look at the end-to-end application lifecycle from an AI Engineer perspective. The process can be broken into three stages: ideation (prompt to prototype), augmentation (prototype to production) and operationalization (performance optimization). </p> <p></p> <p>These stages map loosely onto GenAI Ops toolchains as follows:</p> <ol> <li>Ideation = Getting started, Customization, Prompt Management \u2192  prompt to prototype.</li> <li>Augmentation = Evaluation and Orchestration \u2192  prototype to production</li> <li>Operationalization - Automation and Monitoring \u2192 usage to optimization</li> </ol> <p>In the Hybrid track we used the Azure AI Foundry portal for the initial setup but prioritized the SDK for development and production stages. In this track we'll instead look at each of the toolchains steps with a Portal-first approach.</p>"},{"location":"2-Portal-First/1-Overview/01/#3-retail-rag-scenario","title":"3. Retail RAG scenario","text":"<p>While we can explore the development journey in abstract, it can help to have an application scenario to contextualize and frame the discussion. For convenience, let's repurpose the same application scenario used in the Hybrid Track (summarized below).</p> <p>Some labs (e.g., Model Selection) may be general-purpose and not reflect this specific scenario.</p> <p>Assume that you are building the retail copilot chat AI (backend) that can be accessed from the Contoso Outdoor UI (frontend) shown below. Your chat AI needs to do the following:</p> <ul> <li>Answer customer queries in natural language (= generative AI)</li> <li>Give answers grounded in product data (= RAG design pattern)</li> <li>Give answers that are also coherent, fluent &amp; relevant (= evaluators)</li> <li>Block customer requests that have harmful intent (= content safety)</li> <li>Block customer requests that break the rules (= jailbreak protection)</li> </ul> <p></p> <ul> <li>See: Contoso Outdoor to understand the enterprise retail application scenario.</li> <li>See: Application Data to understand customer, product &amp; manual data formats.</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/","title":"1.3 Azure AI Foundry Portal","text":"<p>In the previous section, we spoke broadly about the Generative AI Operations toolchains in Azure AI. In this section, we'll dive into more details about the Azure AI Foundry platform that streamlines this experience for AI Engineers and application developers.</p> <p></p> <p>Want to get a deeper dive into the details of the platform? Start with these two resources:</p> <ul> <li>Azure AI Foundry Documentation - canonical source.</li> <li>Azure AI Foundry Documentation Markmap - interactive visualization</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/#1-azure-ai-foundry-architecture","title":"1. Azure AI Foundry Architecture","text":"<p>Azure AI Foundry is the recommended platform for E2E development of customizable gen AI apps on Azure</p> <p></p> <ol> <li> <p>The Azure AI Foundry platform provides a unified experience for building, evaluating, and deploying, AI models and applications on Azure.</p> </li> <li> <p>Developers can build applications end-to-end using the web portal (low-code), the SDK (code-first) or the CLI (code-agnostic) based on preferences.</p> </li> <li> <p>The three main components to know are:</p> <ul> <li>Azure OpenAI Service - specialized for use with OpenAI models.</li> <li>Azure AI Foundry Project - richer model catalog, dev tools, security &amp; access controls.</li> <li>Management Center - for configuring AI hub, project, and connected, resources.</li> </ul> </li> </ol>"},{"location":"2-Portal-First/1-Overview/02/#11-azure-openai-resource","title":"1.1 Azure OpenAI Resource","text":"<p>Azure OpenAI Resource is the key to working with OpenAI models.</p> <ul> <li>Use it directly from Azure OpenAI Service or via an Azure AI Foundry project</li> <li>Connect directly (kind=<code>OpenAI</code>) or via AI Services (kind=<code>AIServices</code>) from project.</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/#12-azure-ai-foundry-project","title":"1.2 Azure AI Foundry Project","text":"<p>Azure AI Foundry Project is key to using full range of AI Foundry capabilities </p> <ul> <li>Explore 1800+ models (open-source, frontier, industry) through model catalog</li> <li>Connect to turnkey AI services (language, speech, document intellisense etc.)</li> <li>Connect to content safety services (filtering, jailbreak detection etc.)</li> <li>Connect to data &amp; information retrieval services (AI Search, custom connections)</li> <li>Connect to storage &amp; security services (key vault, log analytics etc.)</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/#13-management-center","title":"1.3 Management Center","text":"FIGURE: View Management Center for an example Azure AI project (click to expand) <p>The Management Center provides a centralized location to manage governance and management tasks for your AI projects. To view the Management Center, visit the Azure AI project page and look for the Management Center option on the sidebar (bottom, left). </p> <p>You can accomplish these tasks from this page:</p> <ol> <li>Manage hubs and projects - create &amp; configure resource at both levels.</li> <li>Manage resource utilization - view and manage quota usage (with metrics)</li> <li>Manage access and governance - add/remove users and assign/remove access roles.</li> </ol>"},{"location":"2-Portal-First/1-Overview/02/#2-resource-types-providers","title":"2. Resource Types &amp; Providers","text":"<p>An Azure resource provider is a set of REST operations that enable functionality for a specific Azure service. Registering resource providers helps you define the Azure resources you can deploy to your account (subscription).</p> REVIEW: Learn about Azure &amp; AI resource providers (click to expand) <p>A resource type's name follows the format: {resource-provider}/{resource-type}. </p> <ul> <li>Example: The resource type for a key vault is <code>Microsoft.KeyVault/vaults</code>.</li> <li>Learn More: Azure resource providers and types</li> <li>Learn More: Azure AI Foundry resource providers and types</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/#1231-ai-resource-providers","title":"1.2.3.1 AI Resource Providers","text":"<p>The Azure AI Foundry is built on the Azure Machine Learning resource provider, and takes a dependency on several other Azure services. </p> REVIEW: list of required resource providers for Azure AI.  (expand to view) <ol> <li><code>Microsoft.MachineLearningServices/workspace (kind=hub)</code> - for hub</li> <li><code>Microsoft.MachineLearningServices/workspace (kind=project)</code> - for project</li> <li><code>Microsoft.CognitiveServices/account (kind=AIServices)</code> - for AI services</li> <li><code>Microsoft.CognitiveServices/account (kind=AIServices OR OpenAI)</code> - for AOAI Service</li> <li><code>Microsoft.Storage/storageAccounts</code> - for storing artifacts</li> <li><code>Microsoft.KeyVault/vaults</code> - for storing secrets</li> </ol> REVIEW: list of additional resource providers useful for RAG.  (click to expand) <ol> <li><code>Microsoft.Search/searchServices</code> - for search &amp; retrieval</li> <li><code>Microsoft.ContainerRegistry/registries</code> - for registering docker images</li> <li><code>Microsoft.Insights/components</code> -  for app insights &amp; log analytics</li> <li><code>Microsoft.OperationalInsights/workspaces</code> - for app insights &amp; log analytics</li> </ol>"},{"location":"2-Portal-First/1-Overview/02/#1232-registering-providers","title":"1.2.3.2 Registering Providers","text":"<p>Some resource providers are registered by default. Others get registered on specific actions (e.g., deploy azd template with providers defined). Others need to be registered manually. You can view and update provider registrations using the Azure Portal or the Azure CLI.</p> <p>Review these links to accomplish these tasks using the Azure Portal (in browser).</p> <ul> <li>View resource provider details - learn what each provider above does</li> <li>Register resource provider - check registration status &amp; register it (if needed)</li> <li>Troubleshoot provider errors - debug causes of common registration errors</li> </ul>"},{"location":"2-Portal-First/1-Overview/02/#124-project-hub-resources","title":"1.2.4 Project &amp; Hub Resources","text":"<p>Hubs and projects are the key to building AI solutions end-to-end on Azure AI Foundry, using its full spectrum of models, tools, and connected resources.</p> <ol> <li>The Azure AI Foundry <code>hub</code> is the top-level resource for managing projects - for admins.</li> <li>The Azure AI Foundry <code>project</code> is the top-level resource for building apps - for developers.</li> <li>The hub creates &amp; configures connected resources - which projects then use seamlessly.</li> <li>Every project must have a parent hub. Every hub may have one or more child projects.</li> <li>Hubs are collaboration environments (team). Projects are development environments (app).</li> </ol> FIGURE: Understand how AI hub, project, and services, resources interact (click to expand) <p></p>"},{"location":"2-Portal-First/1-Overview/02/#126-portals-on-azure","title":"1.2.6 Portals On Azure","text":"<p>Throughout these workshops, you may hear the term \"portal\" used in different contexts. Broadly speaking, \"portal\" refers to a UI-based experience typically via the web browser. We will come across three different portal experiences when building AI applications on Azure.</p> <ol> <li>Azure AI Foundry Portal is for developers. Build generative AI Applications.</li> <li>Azure Machine Learning Studio is for ML Engineers and Data Scientists. Build AI models.</li> <li>Azure Portal is for IT Professionals and Admininstrators. Manage infrastructure.</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/01/","title":"1. Learning Objectives","text":"GENAIOPS: Model Selection is part of the Getting Started stage. (click to view figure) <p>Models are the brains of our generative AI applications. The first step of your end-to-end developer workflow is model selection. This consists of three steps:</p> <ol> <li>Discovery - see if there exists an AI model for your need.</li> <li>Selection - choose the right model from available matches.</li> <li>Usage - deploy, customize, and evaluate, the model for fit.</li> </ol> <p>The Azure AI Foundry portal helps support the model selection journey with three features:</p> <ol> <li>Model catalog - for discovery</li> <li>Model benchmarks - for comparison</li> <li>Model deployment - for evaluation</li> </ol> <p>By the end of this section you should know how to:</p> <ul> <li> Filter the model catalog to discover relevant models</li> <li> Compare selected models using the model benchmarks</li> <li> Select a model and explore its model card for details</li> <li> Start a model deployment to experiment with it in Azure</li> </ul>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/","title":"2. Model Catalog","text":"<p>The Azure AI Foundry model catalog is the starting point for model selection. It currently has 1800+ frontier, industry, and open-source, models that can be filtered by collection, industy, deployment option, inference task, and license. You can also take advantage of the built-in search capability to find models by name or other criteria. Let's explore this.</p> <p>Start by opening a new private browser in guest mode and navigating to the Azure AI Model catalog page in Azure AI Foundry. You should see this: </p> FIGURE: click to expand for example screenshot. Note model count (ex: 1819 models) <p></p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#21-filter-by-inference-task","title":"2.1 Filter By Inference Task","text":"<p>The first step is to see if the catalog has any models that will fit your specific needs. Typically, this will involve knowing the inference task you want to perform, and filtering the catalog to see matching options. Inference tasks can fall under various categories like:</p> <ul> <li>natural language processing (e.g., text generation, question answering),</li> <li>computer vision (e.g., image classification, image segmentation)</li> <li>audio (text-to-speech, audio generation) </li> <li>multimodal (visual question answering, document question answering) etc.</li> </ul> <p>Filter the catalog by a specific inference task to see matching models</p> <ol> <li>Filter by Text generation \u2192 see: 375+ models</li> <li>Filter by Embeddings \u2192 see: 11+ models</li> <li>Filter by Chat completion \u2192 see: 62+ models</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#22-filter-by-deployment-type","title":"2.2 Filter By Deployment Type","text":"<p>Now let's look at the first filter (text generation) - this gives us 375+ results that match. How can we filter this down further? One way is to filter by deployment options. </p> <ul> <li>Managed compute - provides a managed online endpoint (API) in a provisioned VM.</li> <li>Serverless API - provide pay-as-you-go billing and a models-as-a-service (MaaS) approach.</li> </ul> <p>The serverless API option can be more cost-effective and does not consume your model quota while still providing enterprise security and compliance guarantees. Let's try this out:</p> <p>Filter the catalog by a inference task &amp; deployment type to see matching models</p> <ol> <li>First, Filter by Text generation \u2192 see: 375+ models</li> <li>Then, Filter By Serverless API deployment \u2192 see: 3 models (manageable subset)</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#23-filter-by-collection-type","title":"2.3 Filter By Collection Type","text":"<p>Another way to filter models is by collection. At a high level, there are 3 key collections:</p> <ul> <li>Curated by AI - frontier models that have been scanned for vulnerabilities.</li> <li>Hugging Face - open-source model variants from the community</li> <li>Benchmark Results - models that we can compare benchmarks on</li> </ul> <p>You can also select a specific model provider in the collections filter, to see only models from that provider. This is a particularly useful filter to use if you want to prioritize using an open-source model, or want to pick models that you can compare benchmarks on. Let's try it.</p> <p>Filter the catalog by inference task and benchmark results collection to see matching models</p> <ol> <li>First, Filter by Text generation \u2192 see: 375+ models</li> <li>Then, Filter By Benchmark Results collection \u2192 see: 22 models (that I can compare)</li> <li>OR Filter by Hugging Face \u2192 see: 322 models (that are open-source)</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#24-filter-by-industry-domain","title":"2.4 Filter By Industry Domain","text":"<p>Last but not least, we now have a specialized filter for Industry, allowing you to select models that have been specifically curated and tailored for use in vertical domains like Health and Life Sciences, Financial Services etc. Because these are industry-specific, they can be more effective as the first filter for discovery. Let's try it.</p> <p>Filter the catalog by a industry to see matching models</p> <ol> <li>Filter by Financial Services \u2192 see: 10 models including Saifr \u2192 Clear results</li> <li>First,Filter by Health &amp; Life Sciences Industry \u2192 see: 20 models </li> <li>Then, Filter by Embeddings Inference Task \u2192 see: 2 models </li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#25-filter-by-fine-tuning-task","title":"2.5 Filter By Fine-Tuning Task","text":"<p>Model selection is typically followed by model customization - using prompt engineering, retrieval augmented generation, or fine-tuning - to improve the model response to suit your application quality and safety criteria. Fine-tuning works by performing additional training on an existing pre-trained model using a relevant new dataset to enhacne performance or add new skills.</p> <p>Currently only a subset of models in the catalog can be fine-tuned, and these may have added constraints like regional availability for fine-tuning. Let's see how this works.</p> <p>Filter the catalog by for a fine-tuning model for text generation</p> <ol> <li>Filter by Text generation for INFERENCE \u2192 see: 375+ models \u2192 Clear results</li> <li>Filter by Text generation for FINE-TUNING \u2192 see: 14 models</li> <li>Then, Filter by Serverless API Deployment \u2192 see: 3 models (Llama-2)</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/02/#26-search-by-keyword","title":"2.6 Search By Keyword","text":"<p>Sometimes, the predefined filters are not sufficient to reduce the model subset to a manageable level for manual evaluation. This can be for various reasons:</p> <ol> <li>You want to see if the catalog has a specific model name.</li> <li>The model inference task may not be a standard option.</li> <li>You want to see if there are models with a specific capability.</li> </ol> <p>Example 1 (Taxonomy mismatch) - search by category name</p> <ol> <li>First, look for Embeddings inference task. \u2192 see: 10 models (no Hugging Face)</li> <li>Now, search for \"Sentence Similarity\" (HF taxonomy) \u2192 see: 7 open-source models </li> </ol> <p>Example 2 (Known entity) - search by name</p> <ol> <li>Search for \"smol\"  \u2192 see: 1 model = flagship SLM from Hugging Face </li> <li>Search for \"unsloth\"  \u2192 see: 2 models = from specific community creator</li> </ol> <p>Example 3 (Other keywords) - search by capability</p> <ol> <li>Search for \"sql\"  \u2192 see: 2 models = create sql queries using natural language</li> <li>Search for \"biomed\" \u2192 see: models = focus on biomedical applications &amp; data</li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/03/","title":"3. Model Benchmarks","text":""},{"location":"2-Portal-First/2-Setup/01-Model-Selection/03/#31-filter-by-benchmarks","title":"3.1 Filter By Benchmarks","text":"<p>For RAG architectures, we need a chat completion model and an embedding model. To select a model for prototyping, we'll filter by inference task, then look for models with benchmarks, then compare a few by available metrics to make a decision. Let's find our chat model:</p> <ol> <li>Filter by Chat Completion \u2192 see: 62 models </li> <li>Now, Filter by Benchmark Results \u2192 see: 51 models </li> <li> <p>You should see something like this:</p> FIGURE: click to expand for example screenshot <p></p> </li> <li> <p>Click Compare Models \u2192 see: Assess model performance with evaluated metrics </p> </li> </ol> <p>Let's use this page to compare the model options by available benchmarks.</p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/03/#32-compare-by-benchmarks","title":"3.2 Compare By Benchmarks","text":"<p>In the previous step, we saw 51 choices that included the 4 models below. </p> <ul> <li>gpt-4o, gpt-4o-mini, AI21-Jamba-1.5-Mini, and Phi-3-mini-128k-instruct.</li> </ul> <p>Let's use these as a sample for an exercise in using benchmarks for model selection.</p> <ol> <li>The Benchmarks Compare View will have default models selected. Delete the defaults.</li> <li>Now, add the 4 models above (one at a time) using the <code>+ Model to compare</code> button.</li> <li> <p>You should see something like this:</p> FIGURE: click to expand for example screenshot <p></p> </li> <li> <p>Explore the available critera for comparisons (click each drop-down in the chart)</p> <ul> <li>Criteria include: quality, embeddings, cost and latency. </li> </ul> </li> <li>Select Accuracy for x-axis and Cost for y-axis as shown in figure above<ul> <li>The chart will update to show where models fit on this comparison</li> <li>Higher accuracy values - and lower cost values - are better.</li> </ul> </li> <li>Observe the chart. We can see:<ul> <li>the <code>AI21-Jamba-1.5-Mini</code> model costs the least but is also the least accurate</li> <li>the <code>gpt-4o</code> model has the highest accuracy but also the highest cost.</li> <li>the <code>gpt-4o-mini</code> has comparable cost to (1) and is second in accuracy to (2).</li> </ul> </li> <li>Make an informed decision: select <code>gpt-4o-mini</code> <ul> <li>we'll review the Model card in the next section to determine next steps.</li> </ul> </li> </ol> <p>HOMEWORK: Walk through a similar process to select an embedding model.</p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/03/#33-list-by-benchmarks","title":"3.3 List By Benchmarks","text":"<p>The compare view above lets you assess model choices relative to each other based on specific criteria like accuracy, cost and other metrics. The list view provides more detailed metrics for each model, giving insights into their effectiveness for various tasks. Learn more:</p> <ol> <li> <p>Benchmarking of LLMs and SLMs.</p> </li> <li> <p>Benchmarking of embedding models.</p> </li> </ol> <p>Let's explore this briefly for the <code>gpt-4o-mini</code> model we selected earlier.</p> <ol> <li> <p>Search for the model by name as shown below. You should see:</p> <ul> <li>A row of benchmarks for that model, each with a model version and associated dataset</li> <li>Each row has columns for relevant quality metrics (with values, where assessed)</li> <li>The top row provides the average for each metric, across all assessed benchmark</li> </ul> FIGURE: click to expand for example screenshot <p></p> </li> <li> <p>We see this model ranks well on accuracy and prompt-based metrics like coherence, fluency, and groundedness - but does less well on GPTSimilarity. See: Quality docs for explainers on what each metric means. Overall, we see the selected model quality is acceptable.</p> </li> <li> <p>Each row of benchmarks for a model defines a dataset and a task. The dataset contains examples of inputs relevant to the task, along with information to assess quality of model response to that input. The resulting quality metrics are listed in that row. Click on a dataset to get more details on what it does, and how.</p> <ul> <li> <p>Ex 1: Click <code>human_eval</code> which assesses accuracy for Text generation tasks</p> <ul> <li>it assesses functional correctness of code generation from given word problem.</li> <li>it assesses this model at 0.841 accuracy for this text generation task.</li> </ul> FIGURE: (click to expand) Dataset details for <code>HumanEval</code> <p></p> </li> <li> <p>Ex 2: Click <code>squad_v2</code> which assesses groundedness and relevance for QA tasks</p> <ul> <li>it assesses reading comprehension using questions on a Wikipedia dataset.</li> <li>it assesses this model at 4.146 for Groundedness and 3.753 for GPTSimilarity.</li> </ul> FIGURE: (click to expand_ Dataset details for <code>squad_v2</code> <p></p> </li> </ul> </li> </ol> <p>This allows us to get a quick sense of the general suitability of the selected model based on benchmarks. The next step, is to explore the model card.</p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/04/","title":"4. Model Card","text":"<p>The model card for a selected model provides all the necessary information to help you understand its capabilities, pricing, quality and more. And, it provides the starting point for deploying the model to explore it interactively.</p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/04/#41-overview","title":"4.1 Overview","text":"<ol> <li> <p>Click the gpt-4o-mini result to navigate to the model card in Azure.</p> <ul> <li> <p>You should see this - note the links to pricing and estimated cost.</p> FIGURE: (click to expand) Model Card Overview (Details tab - top) <p></p> </li> <li> <p>Scroll down. You see model provider details on tasks and benchmarks of relevance.</p> FIGURE: (click to expand) Model Card Overview (Details tab - bottom) <p></p> </li> </ul> </li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/04/#42-benchmarks","title":"4.2 Benchmarks","text":"<ol> <li> <p>Click the <code>Benchmarks</code> tab in the model card. </p> <ul> <li> <p>The top half of the page provides this view. Clicking Compare with other models takes you to the Benchmarks view from earlier, but with this model as main focus (and other example models for comparison).</p> FIGURE: (click to expand) Benchmarks tab - compare other models <p></p> </li> <li> <p>Scroll down. You should see options to try evaluating the model with your own data.</p> FIGURE: (click to expand) Benchmarks tab - try with your own data <p></p> </li> </ul> </li> </ol>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/04/#43-deployment","title":"4.3 Deployment","text":"<ol> <li> <p>Click the <code>Code samples</code> tab in the model card. You should see code snippets for using this model programmatically with the Azure AI Inference SDK, for various languages. But what if you want to explore this model in a playground in the portal?</p> FIGURE: (click to expand) Code Samples tab - pick your language <p></p> </li> <li> <p>Click the <code>Details</code> tab to get back to the overview (guest mode). Note the <code>Create a subscription to deploy</code> button indicating we need to log into Azure before we can proceed. Let's do that next.</p> FIGURE: (click to expand) Model Card Overview (Guest Mode) <p></p> </li> <li> <p>Logging in gives us a <code>Deploy</code> button as shown. Clicking that now gives you the choice of deploying the model to an existing project, or creating a new project for this purpose.</p> FIGURE: (click to expand) Model Card Overview (Authenticated) <p></p> </li> </ol> <p>In the next lab we'll continue from this point to explore Project setup and model deployment. But first, a quick note on data, privacy, and security considerations when working with models in the Azure AI model catalog.</p>"},{"location":"2-Portal-First/2-Setup/01-Model-Selection/05/","title":"5. Data, Privacy, &amp; Security","text":"<p>When you deploy and customize models in the Azure AI Foundry portal, the service processes data in different contexts. These include:</p> <ol> <li>Prompts - the initial user request, as well as metaprompts and RAG-enhanced context.</li> <li>Generated Content - the response generated by the model, potentially as chat history.</li> <li>Uploaded Data - loaded into a datastore for fine-tuning or other AI customization.</li> <li>Content Filters - analyze prompts and responses to detect and filter harmful content.</li> </ol> <p>Some of the common questions on data security and privacy are:</p> <ul> <li>Is the data stored, shared with providers, or reused for training?</li> <li>Who is processing the data, and what are their data commitments?</li> </ul> <p>To learn more, check out these two core resources:</p> <ol> <li>Data, privacy, and security for use of models through the model catalog</li> <li>Data, privacy, and security for Azure AI Content Safety</li> </ol> <p>This completes the guest tour of the Azure AI Foundry Portal. To explore further capabilities, you will need to login with an Azure subscription (as explored in next section). Let's go!.</p>"},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/01/","title":"1. Learning Objectives","text":"GENAIOPS: Model Exploration is part of the Getting Started stage. (click to view figure) <p>In the previous lab exercises, we learned about model selection by:</p> <ul> <li>Visiting the Azure AI Foundry portal in guest mode.</li> <li>Using the model catalog to discover models that meet your needs</li> <li>Using the model benchmarks to compare relevant models by metrics</li> <li>Using the model card to understand costs, capabilities &amp; code use.</li> </ul> <p>We went from 1800 models to a single candidate. Now, we need to test this model out to see how well it \"fits\" our requuirements. To do this, we need to deploy the model and explore it interactively in a chat playground. Let's see how we can do this in Azure AI Foundry, next.</p> <p>By the end of this section you should know how to:</p> <ul> <li> Deploy a model from an Azure AI model catalog card</li> <li> Create an Azure AI project with a customized hub for this purpose</li> <li> View model deployment details in the Azure AI project</li> <li> View project and hub resource details in the Management center</li> <li> Launch the chat playground for the deployed model (and use it)</li> </ul>"},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/02/","title":"2. Create an AI project","text":"LEARNING RESOURCES: Explore for deeper dives into the topic <ol> <li>Create a project in Azure AI Foundry portal\"</li> <li>How to create a secure Azure AI Foundry hub and project with a managed virtual network\"</li> <li>Management center overview\"</li> </ol>"},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/02/#21-log-into-azure","title":"2.1 Log into Azure","text":"<p>In the Model Card : Deployment section we saw the <code>Create a subscription to deploy</code> button in the card that, when you logged into Azure, changed into a <code>Deploy</code> button. </p> <p>In this section, we'll continue on from that step and assume you have already done the following:</p> <ol> <li>Created an Azure account if needed. Learn more</li> <li>Logged into that Azure account when prompted in this workflow.</li> </ol>"},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/02/#22-create-an-ai-project","title":"2.2 Create an AI project","text":""},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/02/#23-view-management-center","title":"2.3. View Management Center","text":""},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/03/","title":"3. Deploy &amp; Explore Model","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Overview: Deploy AI models in Azure AI Foundry portal\"</li> </ol>"},{"location":"2-Portal-First/2-Setup/02-Model-Exploration/04/","title":"4. Use Chat Playground","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Quickstart: Use the chat playground in Azure AI Foundry portal\"</li> </ol>"},{"location":"2-Portal-First/3-Ideate/01-Model-Customization/01/","title":"1. Learning Objectives","text":"GENAIOPS: Ideation is part of the Customization stage. (click to view figure) <p>In the previous sections we completed model selection and model exploration:</p> <ul> <li>We learned to use the model catalog and benchmarks to \"select\" a model</li> <li>We learned to use model deployment and chat playground to \"explore\" the model</li> </ul> <p>We found the model works for our needs but we do need to ground the responses in our data! It's time to focus on model customization with an emphasis on Retrieval Augmented Generation (RAG) where we add our data to ground model responses. Let's do that, next!</p> <p>By the end of this section you should know how to:</p> <ul> <li> Create and connect an Azure AI Search service to an AI project</li> <li> Create or update RBAC (role access permissions) for resources</li> <li> Add your data to the chat model playground for grounding</li> <li> Test your grounded chat model interactively in playground</li> <li> Deploy that chat prototype as a standalone web application</li> <li> Use the deployed application (with history) or update it</li> </ul>"},{"location":"2-Portal-First/3-Ideate/01-Model-Customization/02/","title":"2. Connect Azure AI Services","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Create an Azure AI search service\"</li> <li>Connect the Azure AI search service to your project\"</li> <li>How to use Azure AI services in Azure AI Foundry portal\"</li> <li>How to use Azure OpenAI Service in Azure AI Foundry portal\"</li> </ol>"},{"location":"2-Portal-First/3-Ideate/01-Model-Customization/03/","title":"3. Create &amp; Update RBAC","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Tutorial: Deploy an enterprise chat web app</li> </ol>"},{"location":"2-Portal-First/3-Ideate/01-Model-Customization/04/","title":"4. Add Grounding Data","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Tutorial: Deploy an enterprise chat web app</li> </ol>"},{"location":"2-Portal-First/3-Ideate/01-Model-Customization/05/","title":"5. Test Grounded Chat","text":"<p>LEARNING RESOURCES: Explore for deeper dives into the topic</p> <ol> <li>Tutorial: Deploy an enterprise chat web app</li> </ol>"},{"location":"2-Portal-First/3-Ideate/02-Model-Integration/01/","title":"1. Learning Objectives","text":"GENAIOPS: Deployment is part of the Production stage. (click to view figure) <p>In the previous sections we completed model selection, exploration and customization:</p> <ul> <li>We learned to use the model catalog and benchmarks to \"select\" a model</li> <li>We learned to use model deployment and chat playground to \"explore\" the model</li> <li>We learned to add search services and data to \"ground\" responses with RAG</li> </ul> <p>We can test the grounded model in the playground, but now we want to get a sense for what a real-world user experience and interaction looks like. Let's deploy the grounded chat model to Azure, then add a web app to interact with it! This is what model integration for real-world use, looks like.</p> <p>By the end of this section you should know how to:</p> <ul> <li> Deploy ground chat prototype as a hosted endpoint (chat API)</li> <li> Deploy a web based application to interact with it (chat UI)</li> <li> Use the deployed application (with history) or update it</li> </ul>"},{"location":"2-Portal-First/3-Ideate/02-Model-Integration/02/","title":"1. Deploy RAG App (Chat AI)","text":""},{"location":"2-Portal-First/3-Ideate/02-Model-Integration/03/","title":"3. Deploy Web App (Chat UI)","text":""},{"location":"2-Portal-First/3-Ideate/02-Model-Integration/04/","title":"4. Chat With Your Data!","text":""},{"location":"2-Portal-First/4-Evaluate/01/","title":"1. \ud83d\udea7 | In Development","text":""},{"location":"2-Portal-First/5-Deploy/01/","title":"1. \ud83d\udea7 | In Development","text":""},{"location":"2-Portal-First/6-Cleanup/01/","title":"1. \ud83d\udea7 | In Development","text":""},{"location":"3-AZD-Template/1-Introduction/01/","title":"1.1 Azure Developer CLI","text":"<p>This section is derived from two resources: the BIntroduction to Azure Developer CLI learn module, and the What is Azure Developer CLI documentation.</p>"},{"location":"3-AZD-Template/1-Introduction/01/#1-azd-cli-tool","title":"1. AZD CLI Tool","text":"<p>The Azure Developer CLI (<code>azd</code>) is described as an open-source tool that:</p> <ul> <li>accelerates provisioning and deploying app resources on Azure</li> <li>with developer-friendly commands for key stages in your development workflow</li> <li>works in the terminal, in your IDE, and in CI/CD pipelines</li> </ul> <p>The <code>azd</code> tool operates on extensible blueprint templates that provide all the information you need (configuration and code) to get applications provisioned, deployed, and running, on Azure. Create a template from scratch or customize and expand one from the Awesome AZD gallery.</p>"},{"location":"3-AZD-Template/1-Introduction/01/#2-azd-template","title":"2. AZD Template","text":"<p>The Azure Developer CLI template has the following components:</p> <ul> <li>Reusable IaC assets. An <code>infra/</code> folder with infrastructure-as-code (IaC) assets using template languages like Bicep (Azure-specific) and Terraform (cloud-agnostic) to define resources for applications. These assets are independent of the application source code - and enable consistent, reproducible deployments of the required infrastructure across users.</li> <li>Starter App code. A <code>src/</code> directory that can be customized or replaced with your own app. This allows you to start with a template that has the right infrastructure configured (which can be complicated for developers) and then focus only on the application development.</li> <li>Configuration files. An <code>azure.yaml</code> configuration file that maps your deployment (services) to provisioned (resources) for the application.</li> <li>Pipeline workflow files (optional). A <code>.github</code> or <code>.azdo/</code> folder configured for automated CI/CD workflows using GitHub Actions or Azure DevOps pipelines. This allows <code>azd</code> to automate redeployments on code changes without manual (commandline) intervention.</li> </ul>"},{"location":"3-AZD-Template/1-Introduction/01/#3-azd-template-workflow","title":"3. AZD Template workflow","text":"<p>The basic steps for using an existing template are:</p> <ol> <li><code>azd init -t &lt;name&gt;</code> \u2192 Initiailize the named template in local folder</li> <li><code>azd\u00a0auth login</code> \u2192 Log into an Azure account targeted for deployment</li> <li><code>azd up</code> \u2192 Provision the resources and deploy the code in 1 command</li> </ol>"},{"location":"3-AZD-Template/1-Introduction/02/","title":"1.2 AZD Templates","text":"<p>This section is derived from two resources: the Deploy and configure Azure Developer CLI templates learn module, and the Azure Developer CLI templates overview documentation.</p> <p>In this section, we answer three questions:</p> <ol> <li>Why should we use Azure Developer CLI templates?</li> <li>How do these templates work?</li> <li>What does a template look like?</li> </ol>"},{"location":"3-AZD-Template/1-Introduction/02/#1-why-use-azd-templates","title":"1. Why use AZD templates?","text":"<p>Developers are used to working with application code. But provisioning resources and deploying applications to the cloud can be a challenging task that often requires the expertise of an IT professional. So how can we streamline the end-to-end development workflow to enable rapid iteration and CI/CD automated workflows for application development?</p> <p>The AZD template defines the infrastructure requirements using Iac (Infrastructure as Code) files that declare the resource requirements, dependencies and configuration in a way that supports:</p> <ul> <li>version control (alongside app codebase)</li> <li>consistent deployment (e.g, across different users)</li> <li>repeatable deployment (for debugging or analysis)</li> </ul> <p>The AZD tool acts on the template, streamlining the process for developers with simple commands that apply best practices at each stage of the development workflow from provisioning to deployment.</p>"},{"location":"3-AZD-Template/1-Introduction/02/#2-how-do-templates-work","title":"2. How do Templates work?","text":"<ol> <li>Instantiate a template using <code>azd init</code> to setup the required files for infrastructure and application source, in your local folder.</li> <li>Authenticate with Azure  using <code>azd auth login</code> to connect your local development environment to an active Azure subscription you can target for deployment.</li> <li>Activate the template with <code>azd up</code> which effectively runs the <code>provision</code> (resources) and <code>deploy</code> (application) commands for you under the hood. These use the infra/ and src/ folders to get the resource and application assets, and the <code>azure.yaml</code> file to understand the relationship between them (app services and dependent resources).</li> </ol>"},{"location":"3-AZD-Template/1-Introduction/02/#3-whats-the-template-structure","title":"3. What's the Template structure?","text":"<p>The typical template consists of a repository with a file structure as shown below. The \"if used\" elements can be considered optional. The <code>src/</code> folder may be created empty - in which case the azd tool will provision the infrastructure and may deploy a placeholder application. </p> <p>The app developer can then refactor the <code>src/</code> folder and invoke <code>azd deploy</code> interactively (or commit changes with a CI/CD workflow established) to have app updates pushed to the pre-provisioned infrastructure - with minimal effort.</p> <pre><code>.azure/          # Azure configurationa and env vars for azd usage\n.azdo/           # Azure DevOps pipelines configuration (if used)\n.devcontainer/.  # Dev Container \"configuration as code\" (if used)\n.github/         # GitHub Actions workflows configuration (if used)\ninfra/           # Bicep or Terraform \"infrastructure as code\" assets\nsrc/             # Deployable app source code (e.g., web/, api/ subfolders)\n.gitignore       # Standard .gitignore behaviors (e.g., `.env` secrets safe)\nazure.yaml       # Maps app services (e.g., web/ api/) to infra resources \nREADME.md        # Describes template usage, app architecture, quickstart\n</code></pre> <p>To get started, you can build off an existing template and customize it - or you can build a new template from your app code from scratch. </p> <p>In the next section, we'll deconstruct an existing azd template for an Azure AI Foundry application to understand the component files. Then we'll explore using that to create an azd template and workflow for the RAG Chat app.</p>"},{"location":"3-AZD-Template/1-Introduction/03/","title":"1.3 Azure AI Template","text":"<p>The Azure AI Foundry Code Preview tab in an active Azue AI project will list 3 azd-capable templates, one of which is the Get started with Azure AI basic starter template. We'll use this as our reference in this tutorial.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#1-before-we-begin","title":"1. Before We Begin","text":"<p>Let's look at what our default folder structure looks like. You should see the following. Make note of this so we can identify the new folders/files that get added when we \"azd init\" the repo.</p> <pre><code>.devcontainer/   # Launch pre-build dev environment in GitHub Codespaces\n.github/         # Add workflows for automated CI/CD actions\ndata/            # Contains data for AI application needs\ndocs/            # Contains documentation for AI application workshop\nsrc.sample/      # Contains app code (working sample)\nenv.sample/      # Contains env variables (placeholder sample)\n.gitignore       # Contains .gitignore rules\nLICENSE          \nmkdocs.yml       # Configuration for mkdocs documentation site\nREADME.md        # README for repo\nREFERENCES.md    # REFERENCES for repo\nrequirements.txt # Python dependencies for application\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#2-view-ai-template","title":"2. View AI Template","text":"<p>Let's take a look at what the folder structure for the Get started with Azure AI basic starter template looks like by visiting that repo:</p> <pre><code>.azdo/pipelines/        # Azure DevOps pipelines \n.devcontainer/          # Dev Container configuration\n.github/                # GitHub Actions workflows\ndocs/                   # README assets and docs\ninfra/                  # Infrastructure-as-code assets\nscripts/                # Scripts for azd hooks \nsrc/                    # Application source\n.gitignore\n.pre-commit-config.yaml # Pre-commit hooks: code quality checks\nLICENSE\nREADME.md\nazure.yaml               # Azure Developer CLI configuration\npyproject.toml           # Python Project configuration\nrequirements-dev.txt     # Python Project package dependencies\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#3-initialize-template","title":"3. Initialize Template","text":"<p>To use that template, we need to run the right azd command in our repo.</p> <p>Note: In this case we are retrofitting an existing sample using the azd template.</p> <p>This means we have to reconcile conflicts in files like <code>.devcontainer.json</code> which get overwritten by the <code>azd init</code> process when using an existing template. This leads to the roundabout process described below. Instead you can also start with an empty repository and initialize the template first - then refactor the contents step by step to reflect your application needs. We can explore that approach later.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#31-create-sandbox","title":"3.1 Create Sandbox","text":"<p>Let's see what happens when we run this at the root of our existing folder:</p> <pre><code>azd init -t azureai-basic-python\n</code></pre> <p>You should see a warning like this:</p> <pre><code>Initializing an app to run on Azure (azd init)\n\nWARNING: The current directory is not empty.\nInitializing an app in this directory may overwrite existing files.\n\n? Continue initializing an app in '/workspaces/azure-ai-rag-workshop'? (y/N) \n</code></pre> <p>We don't want this to happen since we are using the <code>.devcontaine/</code>, <code>.github/</code>, <code>LICENSE</code>, <code>README.md</code> and <code>docs/</code> filenames for our own content. Instead, let's see what happens when we run this in a sandbox directory. We can then compare the contents and move them into the root folder in a more informed manner.</p> <p><pre><code>mkdir SANDBOX\n</code></pre> <pre><code>cd SANDBOX/\n</code></pre></p>"},{"location":"3-AZD-Template/1-Introduction/03/#32-run-azd-init","title":"3.2 Run <code>azd init</code>","text":"<pre><code>azd init -t azureai-basic-python\n</code></pre> <p>You now see something like this:</p> <pre><code>Initializing an app to run on Azure (azd init)\n  (\u2713) Done: Downloading template code to: /workspaces/azure-ai-rag-workshop/SANDBOX\n\n? Enter a new environment name: [? for help] \n</code></pre> <p>At this point, if you view the <code>SANDBOX/</code> folder in the explorer sidebar on VS Code, you will see the file structure from the template view replicated here, along with an empty <code>.azure/</code> folder.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#33-complete-init","title":"3.3 Complete init","text":"<p>Let's continue with the <code>azd init</code> wizard workflow by providing an environment name. Let's pick ragchat-aip as a symbolic name for the RAG Chat app on the Azure AI Platform. You should now see this:</p> <pre><code>? Enter a new environment name: ragchat-aip\n\nSUCCESS: New project initialized!        \nYou can view the template code in your directory: /workspaces/azure-ai-rag-workshop/SANDBOX\nLearn more about running 3rd party code on our DevHub: https://aka.ms/azd-third-party-code-notice\n</code></pre> <p>If you look in the <code>SANDBOX/</code> folder you will now see the <code>.azure/</code> folder is updated:</p> <pre><code>.azure/\n    ragchat-aip/\n        .env             # has: AZURE_ENV_NAME=\"ragchat-aip\"\n        config.json      # is empty\n    .gitignore\n    config.json          # has: {\"version\":1,\"defaultEnvironment\":\"ragchat-aip\"}\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#34-merge-sandbox","title":"3.4 Merge Sandbox","text":"<p>We can now merge the contents from <code>SANDBOX/</code> into the root of the folder in a way that preserves pre-existing files:</p> <pre><code>cd SANDBOX/\nmv .azdo .azure ../.\nmv README.md ../README.azd.md\nmv docs/* ../.\nmv infra scripts src .pre-commit-config.yaml azure.yaml pyproject.toml requirements-dev.txt .gitignire ../.\nmv .github/* ../.github/\nmv .github/workflows/* ../.github/workflows\n</code></pre> <p>Now we need to make a few fixes:</p> <ul> <li> <p>Update the <code>README.azd.md</code> to point to the right location (root) for the two files that were in the docs/ directory but are now at root level - so they resolve correctly.</p> </li> <li> <p>Add these two lines to the end of <code>.gitignore</code> <pre><code># From RAG Chat\nsite/\n.DS_Store\n</code></pre></p> </li> </ul> <p>All that is left is the <code>.devcontainer.json</code> reconciliation. For convenience, just copy these files into the relevant files in <code>.devcontainer/</code> </p> 1. Expand for contents to copy into <code>.devcontainer/devcontainer.json</code> devcontainer.json<pre><code>// Dev Container:\n// Format: https://aka.ms/devcontainer.json. \n// Config: https://github.com/devcontainers/templates/tree/main/src/python\n// Dockerfile Usage: https://containers.dev/guide/dockerfile\n{\n    \"name\": \"azureai-ragchat-azd\",\n    \"build\": {\n        \"dockerfile\": \"Dockerfile\",\n        \"context\": \"..\"\n    },\n    \"features\": {\n        \"ghcr.io/devcontainers/features/azure-cli:1\": {\n            \"installBicep\": true,\n            \"extensions\": \"ml\"\n        },\n        \"ghcr.io/devcontainers/features/git:1\": {},\n        \"ghcr.io/azure/azure-dev/azd:latest\": {},\n        \"ghcr.io/devcontainers/features/docker-in-docker:2\": {},\n        \"ghcr.io/devcontainers/features/github-cli:1\": {},\n        \"ghcr.io/devcontainers/features/node:1\": {\n            \"version\": \"22.8.0\"\n        }\n    },\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"ms-azuretools.azure-dev\",\n                \"ms-azuretools.vscode-bicep\",\n                \"ms-python.python\",\n                \"ms-toolsai.jupyter\",\n                \"GitHub.vscode-github-actions\",\n                \"ms-toolsai.prompty@prerelease\"\n            ]\n        }\n    },\n    \"postCreateCommand\": \"bash .devcontainer/post-create.sh\",\n    \"forwardPorts\": [\n        8000,\n        50505\n    ],\n    \"remoteUser\": \"vscode\",\n    \"hostRequirements\": {\n        \"memory\": \"8gb\"\n    }\n}\n</code></pre> 2. Expand for contents to copy into <code>.devcontainer/Dockerfile</code> Dockerfile<pre><code># Select base Docker image\nFROM mcr.microsoft.com/devcontainers/python:3.11-bullseye\n\n# Combine system &amp; package updates into a single run command\n# Clean up apt cache to reduce image size\nRUN sudo apt-get update &amp;&amp; sudo apt-get install -y \\\n    gcc \\\n    cmake \\\n    pkg-config \\\n    libdbus-1-dev \\\n    libglib2.0-dev \\\n&amp;&amp; python -m pip install --upgrade pip \\\n&amp;&amp; sudo apt-get clean \\\n&amp;&amp; sudo rm -rf /var/lib/apt/lists/*\n\n# Copy requirements.txt and install the Python packages\nCOPY requirements.txt .\nCOPY requirements-dev.txt .\n\n# Install key packages in one layer to reduce image size and build time\nRUN pip install -r requirements.txt \\    \n    &amp;&amp; pip install keyrings.alt dbus-python ipython ipykernel mkdocs-material\n\n# From azd template\nRUN pip install -r requirements-dev.txt &amp;&amp; python3 -m pip install -e  src\n\n# Configure the IPython kernel\nRUN ipython kernel install --name \"python3\" --user\n\n# Install daily version of azd for latest changes\n# See: https://github.com/Azure/azure-dev/tree/main/cli/installer#download-from-daily-builds\nRUN curl -fsSL https://aka.ms/install-azd.sh | bash -s -- --version daily\n\n# ------------ Dev Container configuration -----------------\n# Adapted from https://github.com/Azure-Samples/contoso-chat\n</code></pre> <p>3. We can now delete the <code>SANDBOX/</code> folder.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#4-validate-template","title":"4. Validate Template","text":"<p>Let's see if our merged repository is now an active azd template before we dive into the details and start modifying it!</p>"},{"location":"3-AZD-Template/1-Introduction/03/#41-authenticate","title":"4.1 Authenticate","text":"<p>First authenticate with Azure - use the <code>--use-device-code</code> flag if running in GitHub Codespaces.</p> <pre><code>azd auth login --use-device-code\n</code></pre> <p>Complete the workflow as instructed - you should see this on success:</p> <pre><code>Waiting for you to complete authentication in the browser...\nDevice code authentication completed.\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#42-provision-and-deploy","title":"4.2 Provision and Deploy","text":"<p>Provision and deploy template using the command below. You will be asked to select the subscription and location for deployment. It should then update the <code>.azure/.env</code> file with the relevant parameters, then create a resource group called <code>rg-ragchat-aip</code> in which it will provision the resources and deploy the app.</p> <pre><code>azd up\n</code></pre> TROUBLESHOOTING: Insufficient Quota (expand to view) <ul> <li> <p>You may get an <code>InsufficientQuota</code> error if you pick the wrong location. One way to avoid this is to check Quota and pick a location with available quota.</p> </li> <li> <p>To fix the issue: the simplest option is to </p> <ul> <li><code>azd down --purge</code> (to release all resources created), </li> <li>then update the <code>.env</code> file (to select location with quota). Takes time.</li> <li>then <code>azd up</code> again to complete successful deploy. Takes time.</li> </ul> </li> </ul> <p>You should see something like this for a successful deployment:</p> <pre><code>azd auth login --use-device-code\nStart by copying the next code: BKWTV5URU\nThen press enter and continue to log in from your browser...\n\nWaiting for you to complete authentication in the browser...\nDevice code authentication completed.\nLogged in to Azure as XXXXXXXXXXX\n@nitya \u279c /workspaces/azure-ai-rag-workshop (azdify) $ azd up\n? Enter a new environment name: nitya-ragchat-azd\n? Select an Azure Subscription to use:  XXXXXXXXXXX\n? Select an Azure location to use: 17. (US) East US (eastus)\n\nPackaging services (azd package)\n\n(\u2713) Done: Packaging service api\n\nProvisioning Azure resources (azd provision)\nProvisioning Azure resources can take some time.\n\nSubscription: XXXXXXXXXXX\nLocation: East US\n\nYou can view detailed progress in the Azure Portal:\nhttps://portal.azure.com/#view/HubsExtension/DeploymentDetailsBlade/~/overview/id/XXXXXXXXXXX\n\n(\u2713) Done: Resource group: rg-nitya-ragchat-azd (1.38s)\n(\u2713) Done: Log Analytics workspace: log-26dkr7mmmco62 (16.024s)\n(\u2713) Done: Key Vault: kv-26dkr7mmmco62 (17.236s)\n(\u2713) Done: Application Insights: appi-26dkr7mmmco62 (1.484s)\n(\u2713) Done: Storage account: st26dkr7mmmco62 (20.605s)\n(\u2713) Done: Container Registry: cr26dkr7mmmco62 (22.866s)\n(\u2713) Done: Azure AI Services: aoai-26dkr7mmmco62 (39.461s)\n(\u2713) Done: Azure AI Services Model Deployment: aoai-26dkr7mmmco62/gpt-4o-mini (516ms)\n(\u2713) Done: Azure AI Services Model Deployment: aoai-26dkr7mmmco62/text-embedding-ada-002 (1.067s)\n(\u2713) Done: Machine Learning Workspace: ai-hub-26dkr7mmmco62 (1m36.858s)\n(\u2713) Done: Machine Learning Connection: ai-hub-26dkr7mmmco62/aoai-content-safety-connection (2.424s)\n(\u2713) Done: Machine Learning Connection: ai-hub-26dkr7mmmco62/aoai-26dkr7mmmco62 (2.747s)\n(\u2713) Done: Machine Learning Workspace: ai-project-26dkr7mmmco62 (18.583s)\n(\u2713) Done: Container Apps Environment: containerapps-env-26dkr7mmmco62 (2m24.217s)\n(\u2713) Done: Container App: ca-api-26dkr7mmmco62 (19.817s)\n\nDeploying services (azd deploy)\n\n(\u2713) Done: Deploying service api\n- Endpoint: https://ca-api-26dkr7mmmco62.XXXXXXXXXXX.eastus.azurecontainerapps.io\n\nSUCCESS: Your up workflow to provision and deploy to Azure completed in 6 minutes 58 seconds.\n</code></pre> <p>FAQ: How do resources get a consistent identifier like <code>26dkr7mmmco62</code>?</p> <p>This is one of the useful outcomes from our azd template configuration. The <code>main.bicep</code> file defines a resourceToken variable as shown below, that is then used as a suffix in naming every resource within that group. </p> infra/main.bicep<pre><code>var resourceToken = toLower(uniqueString(subscription().id, environmentName, location))\n</code></pre> <p>The variable is created from a unique hash of the subscription, environment name and location strings for that deployment, reducing the possibility of naming conflicts but also making it easier for us to retrieve resources using a deterministic identifier (defined by resourceToken) later.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#43-environment-vars","title":"4.3 Environment Vars","text":"<p>You should now be able to view the <code>.azure/&lt;env-name&gt;/.env</code> file and see the environment variables defined with values:</p> <pre><code>AZURE_AIPROJECT_CONNECTION_STRING=\"eastus.api.azureml.ms;XXXXXXXXXXX;rg-nitya-ragchat-azd;ai-project-26dkr7mmmco62\"\nAZURE_AI_CHAT_DEPLOYMENT_NAME=\"gpt-4o-mini\"\nAZURE_CONTAINER_ENVIRONMENT_NAME=\"containerapps-env-26dkr7mmmco62\"\nAZURE_CONTAINER_REGISTRY_ENDPOINT=\"cr26dkr7mmmco62.azurecr.io\"\nAZURE_CONTAINER_REGISTRY_NAME=\"cr26dkr7mmmco62\"\nAZURE_ENV_NAME=\"nitya-ragchat-azd\"\nAZURE_LOCATION=\"eastus\"\nAZURE_RESOURCE_GROUP=\"rg-nitya-ragchat-azd\"\nAZURE_SUBSCRIPTION_ID=\"XXXXXXXXXXX\"\nAZURE_TENANT_ID=\"XXXXXXXXXXX\"\nSERVICE_API_ENDPOINTS=\"[\\\"https://ca-api-26dkr7mmmco62.XXXXXXXXXXX.eastus.azurecontainerapps.io\\\"]\"\nSERVICE_API_IDENTITY_PRINCIPAL_ID=\"XXXXXXXXXXX\"\nSERVICE_API_IMAGE_NAME=\"cr26dkr7mmmco62.azurecr.io/azd-aistudio-starter/api-nitya-ragchat-azd:azd-deploy-1740393080\"\nSERVICE_API_NAME=\"ca-api-26dkr7mmmco62\"\nSERVICE_API_RESOURCE_EXISTS=\"false\"\nSERVICE_API_URI=\"https://ca-api-26dkr7mmmco62.XXXXXXXXXXX.eastus.azurecontainerapps.io\"\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#44-local-dev-server","title":"4.4 Local Dev Server","text":"<p>You should now be able to run the local server using the deployed model endpoint as follows:</p> <pre><code>cd src/\npython -m pip install -r requirements.txt\npython -m uvicorn \"api.main:create_app\" --factory --reload\n</code></pre> <p>You should see output like this:</p> <pre><code>@nitya \u279c /workspaces/azure-ai-rag-workshop/src (azdify) $ python -m uvicorn \"api.main:create_app\" --factory --reload\nINFO:     Will watch for changes in these directories: ['/workspaces/azure-ai-rag-workshop/src']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [11197] using WatchFiles\nINFO:     Started server process [11199]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n</code></pre>"},{"location":"3-AZD-Template/1-Introduction/03/#45-local-chat-ui","title":"4.5 Local Chat UI","text":"<p>Open the browser to the local dev server URL identified above. You will see a chat UI as shown.</p> <p></p> <p>Ask questions (at the bottom) and get responses from the default model provisioned (gpt-4o-mini). Note: This default app does not do anything else - it is not grounded in data but is instrumented for analytics with App Insights.</p> <p>Your local development environment has been validated!</p>"},{"location":"3-AZD-Template/1-Introduction/03/#46-azure-portal-resources","title":"4.6 Azure Portal Resources","text":"<p>The <code>azd up</code> command first provisions resources in Azure and then deploys the application. Let's take a quick look at what was provisioned by visiting the Azure Portal and clicking the resource group for this project. Note: Your resource group will be named <code>rg-&lt;env&gt;</code> where the _env reflects the envrionment name chosen during deployment (e.g., \"nitya-ragchat-azd\")</p> <p></p> <p>You should see 11 records that include the following:</p> <ol> <li>An Azure AI hub resource - manage billing, org-level admin</li> <li>An Azure AI project resource - manage state, app-level admin</li> <li>An Azure AI services resource - manage models, turnkey service integrations</li> <li>An Application Insights resource - monitor performance (use in tracing)</li> <li>A Container App resource - hosting chat AI endpoint (FastAPI server)</li> <li>A Container Apps Environment resource - for container app admin</li> <li>A Managed Identity resource - for secure keyless authentication </li> <li>A Key Vault resource - for storing secrets </li> <li>A Log Analytics workspace resource - for logging events </li> <li>A Storage account resource - for storing data (blob, file, queue or table) </li> </ol> <p>Your azd resource provisioning has been validated!</p>"},{"location":"3-AZD-Template/1-Introduction/03/#47-validate-container-app","title":"4.7 Validate Container App","text":"<p>Click on the Container App resource.</p> <ol> <li>Look for the Application Uri property in the \"Essentials\" pane.</li> <li>Click it. It should open a blank site in the browser (maps to empty \"/\" route)</li> <li>Append \"/docs\" to the website URL and hit enter</li> <li>You should see the Swagger API documentation site as shown below:     </li> <li>Click \"Try it Out\" and update the content property value to a question.</li> <li>Verify that the Responses panel shows a relevant result (list of messages).</li> </ol> <p>Your azd app deployment has been validated!</p>"},{"location":"3-AZD-Template/1-Introduction/03/#48-azure-ai-foundry-portal","title":"4.8 Azure AI Foundry Portal","text":"<p>The Azure Portal is used by IT pros and admins to manage resources for your deployment. As a developer, you will likely spend more time in the Azure AI Foundry portal which helps you manage your application state and debug operations when required.</p> <ol> <li>Visit the Azure AI Foundry Portal and click View all projects</li> <li>Use the Columns option to add \"Resource Group\" as a visible column to the table</li> <li>Look for the Azure AI project corresponding to the <code>rg-&lt;env&gt;</code> provisioned - and click.</li> <li>You should see the Project Overview with endpoints and keys information like this. Note the Project connection string - we'll reference it later.     </li> <li>Click the Tracing tab in the sidebar. Verify that you see the screen below. This lets us know the Application Insights resource was successfully deployed for tracing use. To get trace data, we now need to activate tracers in our application code. We'll do that later.     </li> <li>Click the Models + endpoints option on sidebar. You should see a list like this. Verify that azd deployed 2 models: chat and embedding </li> <li>Click the Service endpoints tab in this page. You should see the list of turnkey AI Services that you can now take advantage of using the default project connection string.     </li> <li>Click the chat model (gpt-4o-mini) to view the model details page below. You should be able to vew rate limit details and get access to the endpoint and key values if needed. Note: If you need a higher rate limit - you can use the <code>Edit</code> button to see if your current subscription can support the increase, and update it right here.     </li> <li>Click the \"Metrics\" tab. to see the usage metrics for the model as shown below.     </li> </ol> <p>Note that the panel has an Open in Azure Monitor link at the top. Let's click that now and talk about App Insights and monitoring.</p>"},{"location":"3-AZD-Template/1-Introduction/03/#49-validate-monitoring-works","title":"4.9 Validate Monitoring Works","text":"<ol> <li>This is what you see when you click that link above. You are redirected to the Azure AI Project resource in the Azure Portal, and into the Metrics tab under \"Monitoring\". Use this panel to explore various metrics on performance (e.g., number of requests, latency etc.) for the Azure OpenAI model.     </li> <li>You can also click into the Insights (preview) sidebar option to get this view for Generative AI applications that gives you insights into _token usage, request rate and response latency.     </li> <li>Once you activate tracing in your application, you should also be able to visit the Session Details tab to see activity traces from that session.</li> </ol>"},{"location":"3-AZD-Template/2-RAG-App-Customization/01/","title":"2.1 Explore Template","text":"<p>This section is derived from these resources: </p> <ul> <li>the Azure AI Foundry Starter Template learn module</li> <li>the Use an Azure Resource Manager template to create an Azure AI Foundry hub docs</li> <li>the azd-template-artifacts repo </li> <li>the Bicep documentation</li> <li>the azure-quickstart-templates for aistudio-basics</li> </ul>"},{"location":"3-AZD-Template/2-RAG-App-Customization/02/","title":"2.2 Add App Source","text":""},{"location":"3-AZD-Template/2-RAG-App-Customization/03/","title":"2.3 Create IaC Files","text":""},{"location":"3-AZD-Template/2-RAG-App-Customization/04/","title":"2.4 Update <code>azure.yaml</code>","text":""},{"location":"3-AZD-Template/2-RAG-App-Customization/05/","title":"2.5 Provision &amp; Deploy","text":""},{"location":"3-AZD-Template/2-RAG-App-Customization/06/","title":"2.6 Add CI/CD Pipeline","text":""},{"location":"3-AZD-Template/2-RAG-App-Customization/07/","title":"2.7 Delete &amp; Cleanup","text":""},{"location":"3-AZD-Template/3-Troubleshooting/01/","title":"3.1 Template Creation","text":""},{"location":"3-AZD-Template/3-Troubleshooting/02/","title":"3.2 Template Usage","text":""}]}